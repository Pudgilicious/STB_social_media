tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
# docs <- tm_map(docs, removeWords, stopwords("english")) # Takes to long to run
tdm <- TermDocumentMatrix(docs)
tdm_matrix <- as.matrix(tdm)
words <- sort(rowSums(tdm_matrix), decreasing = TRUE)
words_df <- data.frame(word = names(words), freq = words)
stopwords <- stopwords()
words_df <- subset(words_df, !(word %in% stopwords))
words_df
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
text <- paste(tripa_df$REVIEW_BODY, collapse = " ")
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
# docs <- tm_map(docs, removeWords, stopwords("english")) # Takes to long to run
tdm <- TermDocumentMatrix(docs)
tdm_matrix <- as.matrix(tdm)
words <- sort(rowSums(tdm_matrix), decreasing = TRUE)
words_df <- data.frame(word = names(words), freq = words)
stopwords <- stopwords()
words_df <- subset(words_df, !(word %in% stopwords))
words_df
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 50, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 75, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 90, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(2678) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(34978) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(34978) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 75, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(455) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 75, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(455) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(674239) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.5, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.3, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 80, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 50, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 75, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 75, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(3.5,0.25))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(3.5,0.25))
set.seed(1234) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3.5,0.25))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3.5,0.25))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(1,0.25))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(5,0.25))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3,0.25))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3,0.5))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3, 1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3, 0.2))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(3, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(2, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(5, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(4.5, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.2))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
words_df = subset(words_df, !(word %in% c("singapore", "can")))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 500, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 300, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 250, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 400, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
library(dplyr)
library(tm)
library(stopwords)
library(wordcloud)
library(wordcloud2)
library(dplyr)
library(tm)
library(stopwords)
library(wordcloud)
library(wordcloud2)
wordcloud2(data=words_df, size=1.6, color='random-dark')
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 300, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 350, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
stopwords <- stopwords()
words_df <- subset(words_df, !(word %in% stopwords))
words_df
words_df <- data.frame(word = names(words), freq = words)
stopwords <- stopwords()
words_df <- subset(words_df, !(word %in% stopwords))
words_df
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 325, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
set.seed(1) # for reproducibility
wordcloud(words = words_df$word, freq = words_df$freq, min.freq = 1, max.words = 300, random.order = FALSE, rot.per = 0, colors = brewer.pal(8, "Dark2"), scale=c(4, 0.1))
wordcloud2(data=words_df, size=1.6, color='random-dark')
wordcloud2(data=words_df$word, size=1.6, color='random-dark')
wordcloud2(data=words_df$words, size=1.6, color='random-dark')
wordcloud2(data=(words_df$word), size=1.6, color='random-dark')
wordcloud2(data=words_df, size=1.6, color='random-dark')
knitr::opts_knit$set(root.dir = "~/git/STB_social_media_analytics")
knitr::opts_chunk$set(root.dir = "~/git/STB_social_media_analytics", echo = TRUE)
library(dplyr)
library(tm)
library(stopwords)
library(wordcloud)
library(wordcloud2)
library("topicmodels")
library("ldatuning")
get_docs <- function(text) {
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
return(docs)
}
get_dtm <- function(docs) {
dtm <- TermDocumentMatrix(docs)
dtm_matrix <- as.matrix(dtm)
words <- sort(rowSums(dtm_matrix), decreasing = TRUE)
words_df <- data.frame(word = names(words), freq = words)
stopwords <- stopwords()
words_df <- subset(words_df, !(word %in% stopwords))
words_df
return(words_df)
}
generate_wordcloud <- function(dtm, seed = 1) {
set.seed(seed) # for reproducibility
return(wordcloud(
words = dtm$word,
freq = dtm$freq,
min.freq = 1,
max.words = 300,
random.order = FALSE,
rot.per = 0,
colors = brewer.pal(8, "Dark2"),
scale = c(4, 0.1)
))
}
# Read reviews CSVs in this chunk
tripa_path <- "./tripadvisor/finalised_output/"
folders <- list.files(path = tripa_path, include.dirs = TRUE)
col_names <- c(
"REVIEW_INDEX",
"WEBSITE_INDEX",
"POI_INDEX",
"REVIEWER_URL",
"REVIEW_ID",
"REVIEW_DATE",
"REVIEW_RATING",
"REVIEW_TITLE",
"REVIEW_BODY",
"DATE_OF_EXPERIENCE",
"TRIP_TYPE",
"REVIEW_CRAWLED_TIME"
)
tripa_df <- data.frame(matrix(nrow = 0, ncol = 12))
names(tripa_df) <- col_names
for (folder in folders) {
path <- paste0(tripa_path, folder, "/reviews/")
csv_files <- list.files(path = path)
for (csv_file in csv_files) {
csv_path <- paste0(path, csv_file)
poi_df <- read.csv(csv_path, as.is = TRUE)
tripa_df <- rbind(tripa_df, poi_df)
}
}
summary(tripa_df)
tripa_review_text <- paste(tripa_df$REVIEW_BODY, collapse = " ")
docs1 <- get_docs(tripa_review_text)
dtm1 <- get_dtm(docs1)
generate_wordcloud(dtm1, seed = 1)
# Aspects from TripA
tripa_aspects_path <- "./tripadvisor/aspects_output/"
tripa_aspects_csvs <- list.files(path = tripa_aspects_path, include.dirs = TRUE)[1:3]
tripa_aspects_csvs
tripa_aspects_df <- data.frame(matrix(nrow = 0, ncol = 3))
names(tripa_aspects_df) <- c("POI_INDEX", "ASPECTS", "ASPECTS_CRAWLED_TIME")
for (file_name in tripa_aspects_csvs) {
path <- paste0(tripa_aspects_path, file_name)
aspects_df <- read.csv(path, as.is = TRUE)
tripa_aspects_df <- rbind(tripa_aspects_df, aspects_df)
}
tripa_aspects_text <- paste(tripa_aspects_df$ASPECTS, collapse = " ")
docs2 <- get_docs(tripa_aspects_text)
dtm2 <- get_dtm(docs2)
generate_wordcloud(dtm2, seed = 1)
# Tripadvisor Keywords from IBM
keywords_col_names <- c(
"WEBSITE_ID",
"REVIEW_ID",
"TEXT",
"RELEVANCE",
"COUNT",
"SENTIMENT_SCORE",
"SENTIMENT_LABEL",
"SADNESS",
"JOY",
"FEAR",
"DISGUST",
"ANGER",
"MIXED_SENTIMENT"
)
tripa_keywords_df <- data.frame(matrix(nrow = 0, ncol = 13))
names(tripa_keywords_df) <- keywords_col_names
for (folder in folders) {
path1 <- paste0(tripa_path, folder)
sentiment_folder = list.files(path = path1, include.dirs = TRUE)[4]
path2 <- paste0(tripa_path, folder, "/",sentiment_folder, "/")
csv_files <- list.files(path = path2)
indices <- grep("keywords", csv_files)
for (i in indices) {
csv_path <- paste0(path2, csv_files[i])
poi_df <- read.csv(csv_path, as.is = TRUE)
tripa_keywords_df <- rbind(tripa_keywords_df, poi_df)
}
}
summary(tripa_keywords_df)
tripa_keywords_text <- paste(tripa_keywords_df$TEXT, collapse = " ")
docs3 <- get_docs(tripa_keywords_text)
dtm3 <- get_dtm(docs3)
generate_wordcloud(dtm3, seed = 1)
tripa_aspects_df <- data.frame(matrix(nrow = 0, ncol = 3))
names(tripa_aspects_df) <- c("POI_INDEX", "ASPECTS", "ASPECTS_CRAWLED_TIME")
for (file_name in tripa_aspects_csvs) {
path <- paste0(tripa_aspects_path, file_name)
aspects_df <- read.csv(path, as.is = TRUE)
tripa_aspects_df <- rbind(tripa_aspects_df, aspects_df)
}
summary(tripa_aspects_df)
tripa_review_text <- paste(tripa_df$REVIEW_BODY, collapse = " ")
docs1 <- get_docs(tripa_review_text)
dtm1 <- get_dtm(docs1)
generate_wordcloud(dtm1, seed = 1)
tripa_aspects_text <- paste(tripa_aspects_df$ASPECTS, collapse = " ")
docs2 <- get_docs(tripa_aspects_text)
dtm2 <- get_dtm(docs2)
generate_wordcloud(dtm2, seed = 1)
tripa_keywords_text <- paste(tripa_keywords_df$TEXT, collapse = " ")
docs3 <- get_docs(tripa_keywords_text)
dtm3 <- get_dtm(docs3)
generate_wordcloud(dtm3, seed = 1)
knitr::opts_knit$set(root.dir = "~/git/STB_social_media_analytics")
knitr::opts_chunk$set(root.dir = "~/git/STB_social_media_analytics", echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_knit$set(root.dir = "~/git/STB_social_media_analytics")
knitr::opts_chunk$set(root.dir = "~/git/STB_social_media_analytics", echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
library(dplyr)
library(tm)
library(stopwords)
library(wordcloud)
library(wordcloud2)
library("topicmodels")
library("ldatuning")
get_docs <- function(text) {
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
return(docs)
}
get_dtm <- function(docs) {
dtm <- TermDocumentMatrix(docs)
dtm_matrix <- as.matrix(dtm)
words <- sort(rowSums(dtm_matrix), decreasing = TRUE)
words_df <- data.frame(word = names(words), freq = words)
stopwords <- stopwords()
words_df <- subset(words_df, !(word %in% stopwords))
words_df
return(words_df)
}
generate_wordcloud <- function(dtm, seed = 1) {
set.seed(seed) # for reproducibility
return(wordcloud(
words = dtm$word,
freq = dtm$freq,
min.freq = 1,
max.words = 300,
random.order = FALSE,
rot.per = 0,
colors = brewer.pal(8, "Dark2"),
scale = c(4, 0.1)
))
}
# Read reviews CSVs in this chunk
tripa_path <- "./tripadvisor/finalised_output/"
folders <- list.files(path = tripa_path, include.dirs = TRUE)
col_names <- c(
"REVIEW_INDEX",
"WEBSITE_INDEX",
"POI_INDEX",
"REVIEWER_URL",
"REVIEW_ID",
"REVIEW_DATE",
"REVIEW_RATING",
"REVIEW_TITLE",
"REVIEW_BODY",
"DATE_OF_EXPERIENCE",
"TRIP_TYPE",
"REVIEW_CRAWLED_TIME"
)
tripa_df <- data.frame(matrix(nrow = 0, ncol = 12))
names(tripa_df) <- col_names
for (folder in folders) {
path <- paste0(tripa_path, folder, "/reviews/")
csv_files <- list.files(path = path)
for (csv_file in csv_files) {
csv_path <- paste0(path, csv_file)
poi_df <- read.csv(csv_path, as.is = TRUE)
tripa_df <- rbind(tripa_df, poi_df)
}
}
summary(tripa_df)
tripa_review_text <- paste(tripa_df$REVIEW_BODY, collapse = " ")
docs1 <- get_docs(tripa_review_text)
dtm1 <- get_dtm(docs1)
generate_wordcloud(dtm1, seed = 1)
# Aspects from TripA
tripa_aspects_path <- "./tripadvisor/aspects_output/"
tripa_aspects_csvs <- list.files(path = tripa_aspects_path, include.dirs = TRUE)[1:3]
tripa_aspects_csvs
tripa_aspects_df <- data.frame(matrix(nrow = 0, ncol = 3))
names(tripa_aspects_df) <- c("POI_INDEX", "ASPECTS", "ASPECTS_CRAWLED_TIME")
for (file_name in tripa_aspects_csvs) {
path <- paste0(tripa_aspects_path, file_name)
aspects_df <- read.csv(path, as.is = TRUE)
tripa_aspects_df <- rbind(tripa_aspects_df, aspects_df)
}
summary(tripa_aspects_df)
tripa_aspects_text <- paste(tripa_aspects_df$ASPECTS, collapse = " ")
docs2 <- get_docs(tripa_aspects_text)
dtm2 <- get_dtm(docs2)
generate_wordcloud(dtm2, seed = 1)
# Tripadvisor Keywords from IBM
keywords_col_names <- c(
"WEBSITE_ID",
"REVIEW_ID",
"TEXT",
"RELEVANCE",
"COUNT",
"SENTIMENT_SCORE",
"SENTIMENT_LABEL",
"SADNESS",
"JOY",
"FEAR",
"DISGUST",
"ANGER",
"MIXED_SENTIMENT"
)
tripa_keywords_df <- data.frame(matrix(nrow = 0, ncol = 13))
names(tripa_keywords_df) <- keywords_col_names
for (folder in folders) {
path1 <- paste0(tripa_path, folder)
sentiment_folder = list.files(path = path1, include.dirs = TRUE)[4]
path2 <- paste0(tripa_path, folder, "/",sentiment_folder, "/")
csv_files <- list.files(path = path2)
indices <- grep("keywords", csv_files)
for (i in indices) {
csv_path <- paste0(path2, csv_files[i])
poi_df <- read.csv(csv_path, as.is = TRUE)
tripa_keywords_df <- rbind(tripa_keywords_df, poi_df)
}
}
summary(tripa_keywords_df)
tripa_keywords_text <- paste(tripa_keywords_df$TEXT, collapse = " ")
docs3 <- get_docs(tripa_keywords_text)
dtm3 <- get_dtm(docs3)
generate_wordcloud(dtm3, seed = 1)
generate_wordcloud(dtm1, seed = 1)
generate_wordcloud(dtm2, seed = 1)
generate_wordcloud(dtm3, seed = 1)
install.packages(digest)
install.packages("digest")
install.packages("digest")
knitr::opts_knit$set(root.dir = "~/git/STB_social_media_analytics")
knitr::opts_chunk$set(root.dir = "~/git/STB_social_media_analytics", echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
install.packages("textmineR")
library(textmineR)
dim(dtm2)
dtm = dtm2
tf <- TermDocFreq(dtm = dtm)
m <- FitLdaModel(dtm = dtm2, k = 5, iterations = 500)
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
dim(dtm)
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
dtm)
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
dtm
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
nih_sample
dtm
View(nih_sample)
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(tripa_df$REVIEW_BODY,
doc_names = tripa_df$REVIEW_INDEX,
ngram_window = c(1, 2))
dtm
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
dtm
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
nih_sample
View(nih_sample)
data(nih_sample)
# Create a document term matrix
dtm <- CreateDtm(nih_sample$ABSTRACT_TEXT,
doc_names = nih_sample$APPLICATION_ID,
ngram_window = c(1, 2))
dtm
View(tripa_df)
# Create a document term matrix
dtm <- CreateDtm(tripa_df$REVIEW_BODY,
doc_names = tripa_df$REVIEW_ID,
ngram_window = c(1, 2))
dtm
tf <- TermDocFreq(dtm = dtm)
# Eliminate words appearing less than 2 times or in more than half of the
# documents
vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]
dtm <- dtm[ , vocabulary]
dim(dtm)
# fit some LDA models and select the best number of topics
k_list <- seq(5, 50, by = 5)
model_dir <- paste0("models_", digest::digest(vocabulary, algo = "sha1"))
if (!dir.exists(model_dir)) dir.create(model_dir)
model_list <- TmParallelApply(X = k_list, FUN = function(k){
filename = file.path(model_dir, paste0(k, "_topics.rda"))
if (!file.exists(filename)) {
m <- FitLdaModel(dtm = dtm, k = k, iterations = 500)
m$k <- k
m$coherence <- CalcProbCoherence(phi = m$phi, dtm = dtm, M = 5)
save(m, file = filename)
} else {
load(filename)
}
m
}, export=c("dtm", "model_dir")) # export only needed for Windows machines
# Create a document term matrix
dtm <- CreateDtm(tripa_aspects_df$ASPECTS,
doc_names = tripa_aspects_df$POI_INDEX,
ngram_window = c(1, 2))
dtm
