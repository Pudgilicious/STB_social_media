{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import urllib3\n",
    "import re\n",
    "import mysql.connector\n",
    "import twint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from selenium import webdriver\n",
    "from random import randint\n",
    "from urllib.parse import quote\n",
    "from scrapy import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_url(platform, \n",
    "                  key, \n",
    "                  end_date=datetime.now().strftime('%Y-%m-%d'), \n",
    "                  duration=4):\n",
    "    if platform == 'instagram':\n",
    "        url = 'https://www.instagram.com/graphql/query/?query_hash=1b84447a4d8b6d6d0426fefb34514485&variables='\n",
    "        url += quote('{\"id\":' + '\"' + str(key) + '\"' + ',\"first\":50}')\n",
    "        return url\n",
    "    \n",
    "    if platform == 'twitter':\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        start_date = (end_date - timedelta(days=duration)).strftime('%Y-%m-%d')\n",
    "        end_date = end_date.strftime('%Y-%m-%d')\n",
    "        url = 'https://twitter.com/search?l=&q='\n",
    "        url += quote(key)\n",
    "        url += '%20near%3A%22Singapore%22%20within%3A15mi'\n",
    "        url += '%20since%3A' + start_date + '%20until%3A' + end_date\n",
    "        return url\n",
    "    \n",
    "    else:\n",
    "        print('Error at construct_url(): Please check your platform entry.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(platform, keyword, cursor, data=None, driver=None):\n",
    "    if platform == 'instagram':\n",
    "        for post in data['data']['location']['edge_location_to_media']['edges']:\n",
    "            \n",
    "            # Selecting only the required data.\n",
    "            number_id = post['node']['id']\n",
    "            user_id = post['node']['owner']['id']\n",
    "            timestamp =  datetime.fromtimestamp(post['node']['taken_at_timestamp'])\n",
    "            posted_time = timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            try:\n",
    "                caption = post['node']['edge_media_to_caption']['edges'][0]['node']['text']\n",
    "                caption = re.sub(r'\"', r'\\\"', caption)\n",
    "            except IndexError:\n",
    "                caption = 'None'    \n",
    "\n",
    "            # Insert into MySQL database.\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO instagrams2 (\n",
    "                    number_id,\n",
    "                    user_id,\n",
    "                    keyword,\n",
    "                    posted_time,\n",
    "                    caption\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s);\n",
    "                \"\"\" % (\n",
    "                    '\"' + number_id + '\"',\n",
    "                    '\"' + user_id + '\"',\n",
    "                    '\"' + keyword + '\"',\n",
    "                    '\"' + posted_time + '\"',\n",
    "                    '\"' + caption + '\"'\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if platform == 'twitter':\n",
    "        def convert_tweets_datetime(date_time_str):\n",
    "            return str(datetime.strptime(date_time_str, '%I:%M %p - %d %b %Y'))\n",
    "        \n",
    "        sel = Selector(text=driver.page_source)\n",
    "        tweet_list = sel.xpath('//ol/li[@data-item-type=\"tweet\"]')\n",
    "        \n",
    "        for tweet in tweet_list:\n",
    "            \n",
    "            # Selecting only the required data.\n",
    "            number_id = tweet.xpath('div/div[@class=\"content\"]/div/a/@data-user-id').extract_first()\n",
    "            screen_name = tweet.xpath('div/div[@class=\"content\"]/div/a/span/strong/text()').extract_first()\n",
    "            user_name = tweet.xpath('div/div[@class=\"content\"]/div/a/span/b/text()').extract_first()\n",
    "            posted_time = tweet.xpath('div/div[@class=\"content\"]/div/small[@class=\"time\"]/a/@title').extract_first()\n",
    "            posted_time = convert_tweets_datetime(posted_time)\n",
    "            text_list = tweet.xpath('div/div[@class=\"content\"]/div[@class=\"js-tweet-text-container\"]/*//text()').extract()\n",
    "            text = ''\n",
    "            for j in text_list:\n",
    "                text += j\n",
    "            text = re.sub(r'\"', r'\\\"', text)\n",
    "            if screen_name is None:\n",
    "                screen_name = \"\"\n",
    "            \n",
    "            # Obtaining user location\n",
    "            c = twint.Config()\n",
    "            c.Format = \"{location}\"\n",
    "            c.Store_object = True\n",
    "            c.Hide_output = True\n",
    "            c.Username = user_name\n",
    "            twint.run.Lookup(c)\n",
    "            location = twint.output.users_list[0].location\n",
    "            \n",
    "            # Insert into MySQL database.\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO tweets2 (\n",
    "                    number_id,\n",
    "                    screen_name,\n",
    "                    user_name,\n",
    "                    keyword,\n",
    "                    posted_time,\n",
    "                    tweet,\n",
    "                    location\n",
    "                    )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "                \"\"\" % (\n",
    "                    '\"' + number_id + '\"',\n",
    "                    '\"' + screen_name + '\"',\n",
    "                    '\"' + user_name + '\"',\n",
    "                    '\"' + keyword + '\"',\n",
    "                    '\"' + posted_time + '\"',\n",
    "                    '\"' + text + '\"',\n",
    "                    '\"' + location + '\"'\n",
    "                    )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crawl_instagram():\n",
    "    \n",
    "    # Get poi information into df.\n",
    "    poi_df = pd.read_csv('poi.csv')\n",
    "    pk_list = list(poi_df['pk'])\n",
    "    poi_list = list(poi_df['poi_name'])\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    urllib3.disable_warnings()\n",
    "    \n",
    "    # Initialize MySQL connection and cursor.\n",
    "    cnx = mysql.connector.connect(host='localhost',\n",
    "                                  database='sentimentDB',\n",
    "                                  user='test_user',\n",
    "                                  password='Password123!')\n",
    "    cursor = cnx.cursor(prepared=True)\n",
    "    cursor.execute('SET NAMES utf8mb4')\n",
    "    print('Connection to MySQL server made.\\n')\n",
    "    \n",
    "    for index, pk in enumerate(pk_list):\n",
    "        keyword = poi_list[index]\n",
    "        print(keyword)\n",
    "        url = construct_url(platform='instagram', key=pk)\n",
    "        response = http.request('GET', url)\n",
    "        if response.status == 200:\n",
    "            json_result = json.loads(response.data)\n",
    "            try:\n",
    "                extract_data(platform='instagram', \n",
    "                             keyword=keyword,\n",
    "                             cursor=cursor,\n",
    "                             data=json_result)\n",
    "                cnx.commit()\n",
    "            except TypeError as e:\n",
    "                print('##### EXCEPTION #####')\n",
    "                print(e)\n",
    "                print('#####################')\n",
    "                with open('exception_instagram', 'w') as outfile:\n",
    "                    outfile.write(str(pk) + '\\n')\n",
    "                    sleep(300)\n",
    "\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_twitter(end_date=datetime.now().strftime('%Y-%m-%d'), duration=4):\n",
    "    \n",
    "    # Get poi information into df.\n",
    "    poi_df = pd.read_csv('poi.csv')\n",
    "    pk_list = list(poi_df['pk'])\n",
    "    poi_list = list(poi_df['poi_name'])\n",
    "\n",
    "    # Initialize MySQL connection and cursor.\n",
    "    cnx = mysql.connector.connect(host='localhost',\n",
    "                                  database='sentimentDB',\n",
    "                                  user='test_user',\n",
    "                                  password='Password123!')\n",
    "    cursor = cnx.cursor(prepared=True)\n",
    "    cursor.execute('SET NAMES utf8mb4')\n",
    "    print('Connection to MySQL server made.\\n')\n",
    "        \n",
    "    def load_more_results(driver):\n",
    "        for i in range(10):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            sleep(2)  \n",
    "    \n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    \n",
    "    for keyword in poi_list:\n",
    "        url = construct_url(platform='twitter', \n",
    "                            key=keyword, \n",
    "                            end_date=end_date, \n",
    "                            duration=duration)\n",
    "        print(keyword)\n",
    "        driver.get(url)\n",
    "        sleep(randint(0, 30))\n",
    "        load_more_results(driver)\n",
    "        \n",
    "        try:\n",
    "            extract_data(platform='twitter',\n",
    "                         keyword=keyword,\n",
    "                         cursor=cursor,\n",
    "                         driver=driver)\n",
    "            cnx.commit()\n",
    "        except:\n",
    "            print(\"An error has occured.\")\n",
    "            with open('exception_twitter', 'w') as outfile:\n",
    "                outfile.write(str(keyword) + '\\n')\n",
    "                sleep(300)\n",
    "\n",
    "    driver.quit()\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MySQL server made.\n",
      "\n",
      "Singapore\n",
      "Singapore Flyer\n",
      "Suntec City\n",
      "National Stadium, Singapore\n",
      "Suntec Singapore Convention & Exhibition Centre\n",
      "Singapore Indoor Stadium\n",
      "Pan Pacific Singapore\n",
      "Marina Square\n",
      "CHIJMES\n",
      "Raffles Hotel Singapore\n",
      "Fairmont Singapore\n",
      "The Ritz-Carlton, Millenia Singapore\n",
      "Swissotel The Stamford\n",
      "Mandarin Oriental, Singapore\n",
      "Helix Bridge\n",
      "Singapore Grand Prix\n",
      "Raffles City Singapore\n",
      "Conrad Centennial Singapore\n",
      "InterContinental Singapore\n",
      "Singapore F1 Pit Building\n",
      "##### EXCEPTION #####\n",
      "'NoneType' object is not subscriptable\n",
      "#####################\n",
      "Carlton Hotel Singapore\n",
      "JW Marriott Hotel Singapore South Beach\n",
      "Singapore Management University\n",
      "Marina Mandarin Singapore\n",
      "Switch by Timbre X\n",
      "Gudetama Café Singapore\n",
      "Marina Bay Street Circuit\n",
      "Capitol Singapore\n",
      "Измайловский Кремль\n",
      "Singapore Indoor Stadium\n",
      "National Library Singapore\n",
      "Alive Museum Singapore\n",
      "Andaz Singapore\n",
      "F1 Pit Building\n",
      "Millenia Walk\n",
      "Kallang Wave Mall\n",
      "South Beach, Singapore\n",
      "Aquamarine @ Marina Mandarin Hotel\n",
      "Pasarbella - A Farmers Market at Suntec\n",
      "Fountain of Wealth\n",
      "National Library Board, Singapore\n",
      "Loof\n",
      "Marina Mandarin Singapore\n",
      "Suntec City Mall\n",
      "JAAN\n",
      "Bang Bang\n",
      "Singapore Grand Prix F1 Pit Building\n",
      "The Ritz-Carlton, Millenia Singapore\n",
      "Clinton Street Baking Company, Singapore\n",
      "National Library, Singapore\n",
      "Prive Chijmes\n",
      "Pororo Park Singapore\n",
      "Buffet Town International Buffet Restaurant\n",
      "8Q, Singapore Art Museum\n",
      "NewYork City , USA\n",
      "Suntec City\n",
      "Cathedral of the Good Shepherd\n",
      "Changi International Airport, Singapore\n",
      "Raffles City\n",
      "Paulaner Bräuhaus Singapore\n",
      "Bugis, Singapore\n",
      "Ah Chew Desserts 阿秋甜品\n",
      "Joo Bar\n",
      "Singapore Indoor Stadium\n",
      "Shinji by Kanesaka\n",
      "Anti:dote\n",
      "Standing Sushi Bar\n",
      "Baliza\n",
      "China Jump\n",
      "Mint Museum of Toys\n",
      "Raffles City Convention Centre\n",
      "Golden Village Suntec City\n",
      "Sofra Turkish Cafe & Restaurant\n",
      "Tiong Bahru Bakery\n",
      "CelebFest\n",
      "Drama Centre Theatre\n",
      "Sentosa Singapore\n",
      "Cloud Forest, Garden by the Bay, Singapore\n",
      "Savéur\n",
      "##### EXCEPTION #####\n",
      "'NoneType' object is not subscriptable\n",
      "#####################\n",
      "Gardens by the Bay - Bay East\n",
      "Melt Café at Mandarin Oriental, Singapore\n",
      "Singapore Coffee Festival\n",
      "Angelina Singapore\n",
      "City Harvest Church\n",
      "Food For Thought @ 8Q SAM\n",
      "##### EXCEPTION #####\n",
      "'NoneType' object is not subscriptable\n",
      "#####################\n",
      "@Equinox 70th floor\n",
      "PSB Academy\n",
      "Wah Lok Cantonese Restaurant @ Carlton Hotel\n",
      "Drama Centre Theatre\n",
      "Millenia Tower\n",
      "Emporium Shokuhin\n",
      "##### EXCEPTION #####\n",
      "'NoneType' object is not subscriptable\n",
      "#####################\n",
      "Garibaldi Italian Restaurant & Bar\n",
      "Mink\n",
      "Vatos Urban Tacos\n",
      "SMU Lee Kong Chian School of Business\n",
      "Salted and Hung\n",
      "Affordable Art Fair, Singapore\n",
      "The Cat Museum, Muses & Mansion of Singapore\n",
      "F1 Pit Building\n",
      "Mad for Garlic\n"
     ]
    }
   ],
   "source": [
    "crawl_instagram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MySQL server made.\n",
      "\n",
      "Singapore\n",
      "Singapore Flyer\n",
      "Suntec City\n",
      "National Stadium, Singapore\n",
      "Suntec Singapore Convention & Exhibition Centre\n",
      "Singapore Indoor Stadium\n",
      "Pan Pacific Singapore\n",
      "Marina Square\n",
      "CHIJMES\n",
      "Raffles Hotel Singapore\n",
      "Fairmont Singapore\n",
      "The Ritz-Carlton, Millenia Singapore\n",
      "Swissotel The Stamford\n",
      "Mandarin Oriental, Singapore\n",
      "Helix Bridge\n",
      "Singapore Grand Prix\n",
      "Raffles City Singapore\n",
      "Conrad Centennial Singapore\n",
      "InterContinental Singapore\n",
      "Singapore F1 Pit Building\n",
      "Carlton Hotel Singapore\n",
      "JW Marriott Hotel Singapore South Beach\n",
      "Singapore Management University\n",
      "Marina Mandarin Singapore\n",
      "Switch by Timbre X\n",
      "Gudetama Café Singapore\n",
      "Marina Bay Street Circuit\n",
      "Capitol Singapore\n",
      "Измайловский Кремль\n",
      "Singapore Indoor Stadium\n",
      "National Library Singapore\n",
      "Alive Museum Singapore\n",
      "Andaz Singapore\n",
      "F1 Pit Building\n",
      "Millenia Walk\n",
      "Kallang Wave Mall\n",
      "South Beach, Singapore\n",
      "Aquamarine @ Marina Mandarin Hotel\n",
      "Pasarbella - A Farmers Market at Suntec\n",
      "Fountain of Wealth\n",
      "National Library Board, Singapore\n",
      "Loof\n",
      "Marina Mandarin Singapore\n",
      "Suntec City Mall\n",
      "JAAN\n",
      "Bang Bang\n",
      "Singapore Grand Prix F1 Pit Building\n",
      "The Ritz-Carlton, Millenia Singapore\n",
      "Clinton Street Baking Company, Singapore\n",
      "National Library, Singapore\n",
      "Prive Chijmes\n",
      "Pororo Park Singapore\n",
      "Buffet Town International Buffet Restaurant\n",
      "8Q, Singapore Art Museum\n",
      "NewYork City , USA\n",
      "Suntec City\n",
      "Cathedral of the Good Shepherd\n",
      "Changi International Airport, Singapore\n",
      "Raffles City\n",
      "Paulaner Bräuhaus Singapore\n",
      "Bugis, Singapore\n",
      "Ah Chew Desserts 阿秋甜品\n",
      "Joo Bar\n",
      "Singapore Indoor Stadium\n",
      "Shinji by Kanesaka\n",
      "Anti:dote\n",
      "Standing Sushi Bar\n",
      "Baliza\n",
      "China Jump\n",
      "Mint Museum of Toys\n",
      "Raffles City Convention Centre\n",
      "Golden Village Suntec City\n",
      "Sofra Turkish Cafe & Restaurant\n",
      "Tiong Bahru Bakery\n",
      "CelebFest\n",
      "Drama Centre Theatre\n",
      "Sentosa Singapore\n",
      "Cloud Forest, Garden by the Bay, Singapore\n",
      "Savéur\n",
      "Gardens by the Bay - Bay East\n",
      "Melt Café at Mandarin Oriental, Singapore\n",
      "Singapore Coffee Festival\n",
      "Angelina Singapore\n",
      "City Harvest Church\n",
      "Food For Thought @ 8Q SAM\n",
      "@Equinox 70th floor\n",
      "PSB Academy\n",
      "Wah Lok Cantonese Restaurant @ Carlton Hotel\n",
      "Drama Centre Theatre\n",
      "Millenia Tower\n",
      "Emporium Shokuhin\n",
      "Garibaldi Italian Restaurant & Bar\n",
      "Mink\n",
      "Vatos Urban Tacos\n",
      "SMU Lee Kong Chian School of Business\n",
      "Salted and Hung\n",
      "Affordable Art Fair, Singapore\n",
      "The Cat Museum, Muses & Mansion of Singapore\n",
      "F1 Pit Building\n",
      "Mad for Garlic\n"
     ]
    }
   ],
   "source": [
    "crawl_twitter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
