{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_text = 'vectors.txt'\n",
    "path_to_excel = '20200304_Aspects_Annotation.xlsx'\n",
    "train_size = 400\n",
    "annotated_size = 500\n",
    "count_limit = 5\n",
    "\n",
    "def get_final_dfs(\n",
    "    path_to_text,\n",
    "    path_to_excel,\n",
    "    train_size,\n",
    "    annotated_size,\n",
    "    count_limit\n",
    "):\n",
    "    print(\"Reading .txt and .xlsx...\")\n",
    "    vectors_df, keywords_df = get_parsed_dfs(path_to_text, path_to_excel, count_limit=5)\n",
    "    aspect_categories = get_aspect_categories(keywords_df)\n",
    "    aspect_categories_numbered = dict(zip(range(1, 12), aspect_categories))\n",
    "    no_of_categories = len(aspect_categories)\n",
    "    matrix = get_matrix(vectors_df)\n",
    "    centroids = get_centroids(keywords_df, matrix, aspect_categories, train_size)\n",
    "    print(\"\\nCalculating distances and similarities...\")\n",
    "    manhattan_distances, euclidean_distances, cos_sim, corr = get_distances(\n",
    "        centroids, \n",
    "        matrix, \n",
    "        no_of_categories\n",
    "    )\n",
    "    manhattan_df = parse_to_df(manhattan_distances, vectors_df, no_of_categories)\n",
    "    euclidean_df = parse_to_df(euclidean_distances, vectors_df, no_of_categories)\n",
    "    cos_sim_df = parse_to_df(cos_sim, vectors_df, no_of_categories)\n",
    "    corr_df = parse_to_df(corr, vectors_df, no_of_categories)\n",
    "    \n",
    "    for df in [manhattan_df, euclidean_df]:\n",
    "        df['CLOSEST'] = df.iloc[:,1:no_of_categories+1].apply(\n",
    "            get_closest_index, \n",
    "            axis=1\n",
    "        )\n",
    "        df['PREDICTION'] = [aspect_categories_numbered[x] for x in df['CLOSEST']]\n",
    "\n",
    "    for df in [cos_sim_df, corr_df]:\n",
    "        df['CLOSEST'] = df.iloc[:,1:no_of_categories+1].apply(\n",
    "            get_furthest_index, \n",
    "            axis=1\n",
    "        )\n",
    "        df['PREDICTION'] = [aspect_categories_numbered[x] for x in df['CLOSEST']]\n",
    "    \n",
    "    test_indices = get_test_indices(keywords_df)\n",
    "    for df in [manhattan_df, euclidean_df, cos_sim_df, corr_df]:\n",
    "        get_accuracy(df, test_indices)\n",
    "        \n",
    "    return manhattan_distances, euclidean_distances, cos_sim, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .txt and .xlsx...\n",
      "Activities: 14\n",
      "Environment and Ambience: 24\n",
      "Experience: 24\n",
      "F&B: 19\n",
      "Facilities: 6\n",
      "Family/Children family/ Friends: 13\n",
      "Price: 13\n",
      "Service: 3\n",
      "Shopping: 7\n",
      "Sightseeing/ Place: 103\n",
      "Transportation and Accessibility: 51\n",
      "\n",
      "Centroids found.\n",
      "\n",
      "Calculating distances and similarities...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'no_of_categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-59d7c005f4c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mannotated_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcount_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-48-8e8657742fc5>\u001b[0m in \u001b[0;36mget_final_dfs\u001b[0;34m(path_to_text, path_to_excel, train_size, annotated_size, count_limit)\u001b[0m\n\u001b[1;32m     33\u001b[0m         df['CLOSEST'] = df.iloc[:,1:no_of_categories+1].apply(\n\u001b[1;32m     34\u001b[0m             \u001b[0mget_closest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         )\n\u001b[1;32m     37\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PREDICTION'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maspect_categories_numbered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CLOSEST'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[0;32m--> 296\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-677ef4d3ad73>\u001b[0m in \u001b[0;36mget_closest_index\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_closest_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_of_categories\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_furthest_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'no_of_categories' is not defined"
     ]
    }
   ],
   "source": [
    "get_final_dfs(\n",
    "    path_to_text,\n",
    "    path_to_excel,\n",
    "    train_size,\n",
    "    annotated_size,\n",
    "    count_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_df(path_to_text): \n",
    "    vectors_df = pd.read_csv(path_to_text, delim_whitespace=True, header=None)\n",
    "    parsed_col = []\n",
    "    for keyword in list(vectors_df[0]):\n",
    "        keyword = str(keyword)\n",
    "        keyword = keyword.replace('_', ' ')\n",
    "        parsed_col.append(keyword)\n",
    "    vectors_df[0] = parsed_col\n",
    "    vectors_df.columns = ['TEXT'] + list(range(1, vectors_df.shape[1]))\n",
    "    return vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_df(path_to_excel, count_limit): \n",
    "    keywords_df = pd.read_excel(path_to_excel)\n",
    "    keywords_df = keywords_df[keywords_df['count'] >= count_limit]\n",
    "    parsed_col_2 = []\n",
    "    for keyword in list(keywords_df['TEXT']):\n",
    "        keyword = str(keyword)\n",
    "        keyword = keyword.replace('â€™', \"'\")\n",
    "        keyword = keyword.replace('ã©', 'é')\n",
    "        parsed_col_2.append(keyword)\n",
    "    keywords_df['TEXT'] = parsed_col_2\n",
    "    keywords_df.drop_duplicates('TEXT', inplace=True) # There are duplicates after the .replace() functions\n",
    "    return keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parsed_dfs(path_to_text, path_to_excel, count_limit=5):\n",
    "    vectors_df = get_vectors_df(path_to_text)\n",
    "    keywords_df = get_keywords_df(path_to_excel, count_limit=count_limit)\n",
    "    joint_df = vectors_df.merge(keywords_df)\n",
    "    vectors_df = joint_df.iloc[:, :vectors_df.shape[1]]\n",
    "    keywords_df = joint_df.iloc[:, vectors_df.shape[1]:]\n",
    "    return vectors_df, keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(vectors_df):\n",
    "    return vectors_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(matrix):\n",
    "    return np.mean(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manhattan(a, b):\n",
    "    return np.abs(a - b).sum()\n",
    "\n",
    "def get_euclidean(a, b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def get_cos_sim(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def get_corr(a, b):\n",
    "    return np.correlate(a, b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_categories(keywords_df):\n",
    "    aspect_categories = list(set(keywords_df.ASPECT_CATEGORY_NAME))\n",
    "    aspect_categories = [x for x in aspect_categories if x is not np.nan]\n",
    "    aspect_categories.sort()\n",
    "    return aspect_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(keywords_df, matrix, aspect_categories, train_size=400):\n",
    "    df_train = keywords_df.iloc[:train_size, :]\n",
    "    no_of_categories = len(aspect_categories)\n",
    "    centroids = np.zeros((no_of_categories, 300))\n",
    "    for i in range(no_of_categories):\n",
    "        indices = df_train[df_train.ASPECT_CATEGORY_NAME == aspect_categories[i]].index\n",
    "        print('{}: {}'.format(aspect_categories[i], len(indices)))\n",
    "        centroids[i] = get_centroid(matrix[indices])\n",
    "    print('\\nCentroids found.')\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(centroids, matrix, no_of_categories):  # Returns tuple of 4 matrices\n",
    "    manhattan_distances = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    euclidean_distances = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    cos_sim = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    corr = np.zeros((matrix.shape[0], no_of_categories))\n",
    "\n",
    "    def get_distances(centroids, matrix):\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(no_of_categories):\n",
    "                manhattan_distances[i, j] = get_manhattan(matrix[i], centroids[j])\n",
    "\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(no_of_categories):\n",
    "                euclidean_distances[i, j] = get_euclidean(matrix[i], centroids[j])\n",
    "\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(no_of_categories):\n",
    "                cos_sim[i, j] = get_cos_sim(matrix[i], centroids[j])\n",
    "\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(no_of_categories):\n",
    "                corr[i, j] = get_corr(matrix[i], centroids[j])\n",
    "                \n",
    "    return manhattan_distances, euclidean_distances, cos_sim, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_df(matrix, vectors_df, no_of_categories):\n",
    "    final_df = pd.DataFrame(data=matrix)\n",
    "    final_df['KEYWORD'] = vectors_df.TEXT\n",
    "    cols = ['KEYWORD'] + [i for i in range(no_of_categories)]\n",
    "    colnames = ['KEYWORD'] + [i for i in range(1, no_of_categories+1)]\n",
    "    final_df = final_df.loc[:, cols]\n",
    "    final_df.columns = colnames\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_index(row):\n",
    "    dictionary = dict(zip(row, list(range(1, no_of_categories+1))))\n",
    "    return dictionary[min(row)]\n",
    "\n",
    "def get_furthest_index(row):\n",
    "    dictionary = dict(zip(row, list(range(1, no_of_categories+1))))\n",
    "    return dictionary[max(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_indices(df):\n",
    "    temp_df = df.iloc[train_size:annotated_size, :]\n",
    "    return temp_df[temp_df.ASPECT_CATEGORY_NAME.isin(aspect_categories)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, test_indices):\n",
    "    sum = (model.PREDICTION[test_indices] == keywords_df.ASPECT_CATEGORY_NAME[test_indices]).sum()\n",
    "    print(\"Accuracy: {}\".format(sum/len(test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
