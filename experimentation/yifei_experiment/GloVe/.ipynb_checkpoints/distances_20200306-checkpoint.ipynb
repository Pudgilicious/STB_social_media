{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_text = 'vectors.txt'\n",
    "path_to_excel = '20200304_Aspects_Annotation.xlsx'\n",
    "train_size = 400\n",
    "annotated_size = 500\n",
    "count_limit = 5\n",
    "\n",
    "def get_final_dfs(\n",
    "    path_to_text,\n",
    "    path_to_excel,\n",
    "    train_size,\n",
    "    annotated_size,\n",
    "    count_limit\n",
    "):\n",
    "    vectors_df, keywords_df = get_parsed_dfs(path_to_text, path_to_excel, count_limit=5)\n",
    "    aspect_categories = get_aspect_categories(keywords_df)\n",
    "    aspect_categories_numbered = dict(zip(range(1, 12), aspect_categories))\n",
    "    no_of_categories = len(aspect_categories)\n",
    "    matrix = get_matrix(vectors_df)\n",
    "    centroids = get_centroids(keywords_df, matrix, aspect_categories, train_size)\n",
    "    print(\"\\nCalculating distances and similarities...\")\n",
    "    manhattan_distances, euclidean_distances, cos_sim, corr = get_distances(\n",
    "        centroids, \n",
    "        matrix, \n",
    "        no_of_categories\n",
    "    )\n",
    "    manhattan_df = parse_to_df(manhattan_distances, vectors_df, no_of_categories)\n",
    "    euclidean_df = parse_to_df(euclidean_distances, vectors_df, no_of_categories)\n",
    "    cos_sim_df = parse_to_df(cos_sim, vectors_df, no_of_categories)\n",
    "    corr_df = parse_to_df(corr, vectors_df, no_of_categories)\n",
    "    \n",
    "    def get_closest_index(row):\n",
    "        dictionary = dict(zip(row, list(range(1, no_of_categories+1))))\n",
    "        return dictionary[min(row)]\n",
    "\n",
    "    def get_furthest_index(row):\n",
    "        dictionary = dict(zip(row, list(range(1, no_of_categories+1))))\n",
    "        return dictionary[max(row)]\n",
    "    \n",
    "    for df in [manhattan_df, euclidean_df]:\n",
    "        df['CLOSEST'] = df.iloc[:, 1:no_of_categories+1].apply(\n",
    "            get_closest_index, \n",
    "            axis=1\n",
    "        )\n",
    "        df['PREDICTION'] = [aspect_categories_numbered[x] for x in df['CLOSEST']]\n",
    "\n",
    "    for df in [cos_sim_df, corr_df]:\n",
    "        df['CLOSEST'] = df.iloc[:, 1:no_of_categories+1].apply(\n",
    "            get_furthest_index, \n",
    "            axis=1\n",
    "        )\n",
    "        df['PREDICTION'] = [aspect_categories_numbered[x] for x in df['CLOSEST']]\n",
    "    \n",
    "    test_indices = get_test_indices(keywords_df, annotated_size, aspect_categories)\n",
    "    for df in [manhattan_df, euclidean_df, cos_sim_df, corr_df]:\n",
    "        get_accuracy(df, keywords_df, test_indices)\n",
    "        \n",
    "    return manhattan_distances, euclidean_distances, cos_sim, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .txt and .xlsx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyf0717/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities: 12\n",
      "Environment and Ambience: 16\n",
      "Experience: 16\n",
      "F&B: 24\n",
      "Facilities: 4\n",
      "Family/Children family/ Friends: 12\n",
      "Price: 10\n",
      "Service: 4\n",
      "Shopping: 10\n",
      "Sightseeing/ Place: 130\n",
      "Transportation and Accessibility: 46\n",
      "\n",
      "Centroids found.\n",
      "\n",
      "Calculating distances and similarities...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-59d7c005f4c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mannotated_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcount_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-2-b7bc6d0fac1e>\u001b[0m in \u001b[0;36mget_final_dfs\u001b[0;34m(path_to_text, path_to_excel, train_size, annotated_size, count_limit)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mno_of_categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m     \u001b[0mmanhattan_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanhattan_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_of_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-98b4442e17e8>\u001b[0m in \u001b[0;36mget_distances\u001b[0;34m(centroids, matrix, no_of_categories)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_of_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mmanhattan_distances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_manhattan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5364e2dec0a4>\u001b[0m in \u001b[0;36mget_manhattan\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_manhattan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_euclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "get_final_dfs(\n",
    "    path_to_text,\n",
    "    path_to_excel,\n",
    "    train_size,\n",
    "    annotated_size,\n",
    "    count_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_df(path_to_text): \n",
    "    vectors_df = pd.read_csv(path_to_text, delim_whitespace=True, header=None)\n",
    "    parsed_col = []\n",
    "    for keyword in list(vectors_df[0]):\n",
    "        keyword = str(keyword)\n",
    "        keyword = keyword.replace('_', ' ')\n",
    "        parsed_col.append(keyword)\n",
    "    vectors_df[0] = parsed_col\n",
    "    vectors_df.columns = ['TEXT'] + list(range(1, vectors_df.shape[1]))\n",
    "    return vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_df(path_to_excel, count_limit): \n",
    "    keywords_df = pd.read_excel(path_to_excel)\n",
    "    keywords_df = keywords_df[keywords_df['count'] >= count_limit]\n",
    "    parsed_col_2 = []\n",
    "    for keyword in list(keywords_df['TEXT']):\n",
    "        keyword = str(keyword)\n",
    "        keyword = keyword.replace('â€™', \"'\")\n",
    "        keyword = keyword.replace('ã©', 'é')\n",
    "        parsed_col_2.append(keyword)\n",
    "    keywords_df['TEXT'] = parsed_col_2\n",
    "    keywords_df.drop_duplicates('TEXT', inplace=True) # There are duplicates after the .replace() functions\n",
    "    return keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parsed_dfs(path_to_text, path_to_excel, count_limit=5):\n",
    "    vectors_df = get_vectors_df(path_to_text)\n",
    "    keywords_df = get_keywords_df(path_to_excel, count_limit=count_limit)\n",
    "    joint_df = vectors_df.merge(keywords_df)\n",
    "    vectors_df = joint_df.iloc[:, :vectors_df.shape[1]]\n",
    "    keywords_df = joint_df.iloc[:, vectors_df.shape[1]:]\n",
    "    return vectors_df, keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(vectors_df):\n",
    "    return vectors_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(matrix):\n",
    "    return np.mean(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manhattan(a, b):\n",
    "    return np.abs(a - b).sum()\n",
    "\n",
    "def get_euclidean(a, b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def get_cos_sim(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def get_corr(a, b):\n",
    "    return np.correlate(a, b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_categories(keywords_df):\n",
    "    aspect_categories = list(set(keywords_df.ASPECT_CATEGORY_NAME))\n",
    "    aspect_categories = [x for x in aspect_categories if x is not np.nan]\n",
    "    aspect_categories.sort()\n",
    "    return aspect_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(keywords_df, matrix, aspect_categories, train_size=400):\n",
    "    df_train = keywords_df.iloc[:train_size, :]\n",
    "    no_of_categories = len(aspect_categories)\n",
    "    centroids = np.zeros((no_of_categories, 300))\n",
    "    for i in range(no_of_categories):\n",
    "        indices = df_train[df_train.ASPECT_CATEGORY_NAME == aspect_categories[i]].index\n",
    "        print('{}: {}'.format(aspect_categories[i], len(indices)))\n",
    "        centroids[i] = get_centroid(matrix[indices])\n",
    "    print('\\nCentroids found.')\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(centroids, matrix, no_of_categories):  # Returns tuple of 4 matrices\n",
    "    manhattan_distances = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    euclidean_distances = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    cos_sim = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    corr = np.zeros((matrix.shape[0], no_of_categories))\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            manhattan_distances[i, j] = get_manhattan(matrix[i], centroids[j])\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            euclidean_distances[i, j] = get_euclidean(matrix[i], centroids[j])\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            cos_sim[i, j] = get_cos_sim(matrix[i], centroids[j])\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            corr[i, j] = get_corr(matrix[i], centroids[j])\n",
    "                \n",
    "    return manhattan_distances, euclidean_distances, cos_sim, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_df(matrix, vectors_df, no_of_categories):\n",
    "    final_df = pd.DataFrame(data=matrix)\n",
    "    final_df['KEYWORD'] = vectors_df.TEXT\n",
    "    cols = ['KEYWORD'] + [i for i in range(no_of_categories)]\n",
    "    colnames = ['KEYWORD'] + [i for i in range(1, no_of_categories+1)]\n",
    "    final_df = final_df.loc[:, cols]\n",
    "    final_df.columns = colnames\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_indices(df, annotated_size, aspect_categories):\n",
    "    temp_df = df.iloc[train_size:annotated_size, :]\n",
    "    return temp_df[temp_df.ASPECT_CATEGORY_NAME.isin(aspect_categories)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, keywords_df, test_indices):\n",
    "    sum = (model.PREDICTION[test_indices] == keywords_df.ASPECT_CATEGORY_NAME[test_indices]).sum()\n",
    "    print(\"Accuracy: {}\".format(sum/len(test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
