{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_text = 'vectors.txt'\n",
    "path_to_excel = '20200304_Aspects_Annotation.xlsx'\n",
    "train_size = 400\n",
    "annotated_size = 500\n",
    "count_limit = 5\n",
    "\n",
    "def get_final_dfs(\n",
    "    path_to_text,\n",
    "    path_to_excel,\n",
    "    train_size,\n",
    "    annotated_size,\n",
    "    count_limit\n",
    "):\n",
    "    print(\"Reading .txt and .xlsx...\")\n",
    "    vectors_df, keywords_df = get_parsed_dfs(path_to_text, path_to_excel, count_limit=5)\n",
    "    aspect_categories = get_aspect_categories(keywords_df)\n",
    "    aspect_categories_numbered = dict(zip(range(1, 12), aspect_categories))\n",
    "    no_of_categories = len(aspect_categories)\n",
    "    matrix = get_matrix(vectors_df)\n",
    "    centroids = get_centroids(keywords_df, matrix, aspect_categories, train_size)\n",
    "    print(\"\\nCalculating distances and similarities...\")\n",
    "    manhattan_distances, euclidean_distances, cos_sim, corr = get_distances(\n",
    "        centroids, \n",
    "        matrix, \n",
    "        no_of_categories\n",
    "    )\n",
    "    manhattan_df = parse_to_df(manhattan_distances, vectors_df, no_of_categories)\n",
    "    euclidean_df = parse_to_df(euclidean_distances, vectors_df, no_of_categories)\n",
    "    cos_sim_df = parse_to_df(cos_sim, vectors_df, no_of_categories)\n",
    "    corr_df = parse_to_df(corr, vectors_df, no_of_categories)\n",
    "    \n",
    "    def get_closest_index(row):\n",
    "        dictionary = dict(zip(row, list(range(1, no_of_categories+1))))\n",
    "        return dictionary[min(row)]\n",
    "\n",
    "    def get_furthest_index(row):\n",
    "        dictionary = dict(zip(row, list(range(1, no_of_categories+1))))\n",
    "        return dictionary[max(row)]\n",
    "    \n",
    "    for df in [manhattan_df, euclidean_df]:\n",
    "        df['CLOSEST'] = df.iloc[:, 1:no_of_categories+1].apply(\n",
    "            get_closest_index, \n",
    "            axis=1\n",
    "        )\n",
    "        df['PREDICTION'] = [aspect_categories_numbered[x] for x in df['CLOSEST']]\n",
    "\n",
    "    for df in [cos_sim_df, corr_df]:\n",
    "        df['CLOSEST'] = df.iloc[:, 1:no_of_categories+1].apply(\n",
    "            get_furthest_index, \n",
    "            axis=1\n",
    "        )\n",
    "        df['PREDICTION'] = [aspect_categories_numbered[x] for x in df['CLOSEST']]\n",
    "    \n",
    "    test_indices = get_test_indices(keywords_df, annotated_size, aspect_categories)\n",
    "    for df in [manhattan_df, euclidean_df, cos_sim_df, corr_df]:\n",
    "        get_accuracy(df, keywords_df, test_indices)\n",
    "        \n",
    "    return manhattan_distances, euclidean_distances, cos_sim, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .txt and .xlsx...\n",
      "Activities: 14\n",
      "Environment and Ambience: 24\n",
      "Experience: 24\n",
      "F&B: 19\n",
      "Facilities: 6\n",
      "Family/Children family/ Friends: 13\n",
      "Price: 13\n",
      "Service: 3\n",
      "Shopping: 7\n",
      "Sightseeing/ Place: 103\n",
      "Transportation and Accessibility: 51\n",
      "\n",
      "Centroids found.\n",
      "\n",
      "Calculating distances and similarities...\n",
      "Accuracy: 0.43548387096774194\n",
      "Accuracy: 0.5161290322580645\n",
      "Accuracy: 0.532258064516129\n",
      "Accuracy: 0.3225806451612903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 99.428299  ,  98.53062779, 101.93011804, ..., 104.17046514,\n",
       "          95.94584806, 101.11645671],\n",
       "        [112.31006829, 111.47379187, 110.52465696, ..., 110.35272357,\n",
       "         107.4549956 , 111.1347128 ],\n",
       "        [127.23106543, 117.35154612, 119.56580979, ..., 131.12888243,\n",
       "         115.42459671, 119.59029398],\n",
       "        ...,\n",
       "        [ 46.99797986,  41.71392304,  37.53582204, ...,  56.115556  ,\n",
       "          41.99152295,  40.66729643],\n",
       "        [ 46.95517471,  42.54350446,  38.64664404, ...,  55.713542  ,\n",
       "          42.68226146,  43.02745333],\n",
       "        [ 48.28976971,  44.59756288,  39.29774437, ...,  59.44166729,\n",
       "          44.48785826,  44.06154402]]),\n",
       " array([[6.94715529, 7.00892117, 7.20183371, ..., 7.53926982, 6.78436462,\n",
       "         7.1271808 ],\n",
       "        [8.45263651, 8.37220199, 8.32221661, ..., 8.39437269, 8.0810994 ,\n",
       "         8.32961824],\n",
       "        [8.93338398, 8.46891214, 8.53837177, ..., 9.37955128, 8.28189415,\n",
       "         8.55895532],\n",
       "        ...,\n",
       "        [3.37224009, 3.02121007, 2.70218398, ..., 4.19544523, 3.02052042,\n",
       "         2.89751131],\n",
       "        [3.40134604, 3.06117363, 2.81326965, ..., 4.17847527, 3.09070583,\n",
       "         3.09242693],\n",
       "        [3.52569632, 3.22751395, 2.81477231, ..., 4.42226441, 3.18476701,\n",
       "         3.14508949]]),\n",
       " array([[ 0.52964045,  0.53038424,  0.48802171, ...,  0.37503519,\n",
       "          0.60483118,  0.49502482],\n",
       "        [ 0.44171419,  0.48370272,  0.5294822 , ...,  0.44017737,\n",
       "          0.58194236,  0.50075966],\n",
       "        [ 0.33845108,  0.49744192,  0.5015084 , ...,  0.23798508,\n",
       "          0.5621954 ,  0.47081493],\n",
       "        ...,\n",
       "        [-0.42096351, -0.36991044, -0.36024564, ..., -0.283647  ,\n",
       "         -0.45149406, -0.22169191],\n",
       "        [-0.48330321, -0.45227591, -0.58021115, ..., -0.25990454,\n",
       "         -0.59393798, -0.58934013],\n",
       "        [-0.54036342, -0.57861686, -0.42018206, ..., -0.53553267,\n",
       "         -0.58252267, -0.51298169]]),\n",
       " array([[13.12528561, 11.74071872,  9.54300503, ..., 12.05039475,\n",
       "         13.16421744, 10.79093217],\n",
       "        [12.68405677, 12.40714347, 11.99738452, ..., 16.38876285,\n",
       "         14.67675514, 12.64883504],\n",
       "        [ 9.86940279, 12.95727877, 11.53962157, ...,  8.99800685,\n",
       "         14.39844218, 12.07673566],\n",
       "        ...,\n",
       "        [-0.78384217, -0.61525793, -0.52929927, ..., -0.68480039,\n",
       "         -0.73836223, -0.36311015],\n",
       "        [-0.88746688, -0.74184365, -0.84069206, ..., -0.61879668,\n",
       "         -0.95787057, -0.95192528],\n",
       "        [-1.22466228, -1.17138037, -0.75142615, ..., -1.57368574,\n",
       "         -1.15951533, -1.02267262]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_dfs(\n",
    "    path_to_text,\n",
    "    path_to_excel,\n",
    "    train_size,\n",
    "    annotated_size,\n",
    "    count_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_df(path_to_text): \n",
    "    vectors_df = pd.read_csv(path_to_text, delim_whitespace=True, header=None)\n",
    "    parsed_col = []\n",
    "    for keyword in list(vectors_df[0]):\n",
    "        keyword = str(keyword)\n",
    "        keyword = keyword.replace('_', ' ')\n",
    "        parsed_col.append(keyword)\n",
    "    vectors_df[0] = parsed_col\n",
    "    vectors_df.columns = ['TEXT'] + list(range(1, vectors_df.shape[1]))\n",
    "    return vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_df(path_to_excel, count_limit): \n",
    "    keywords_df = pd.read_excel(path_to_excel)\n",
    "    keywords_df = keywords_df[keywords_df['count'] >= count_limit]\n",
    "    parsed_col_2 = []\n",
    "    for keyword in list(keywords_df['TEXT']):\n",
    "        keyword = str(keyword)\n",
    "        keyword = keyword.replace('â€™', \"'\")\n",
    "        keyword = keyword.replace('ã©', 'é')\n",
    "        parsed_col_2.append(keyword)\n",
    "    keywords_df['TEXT'] = parsed_col_2\n",
    "    keywords_df.drop_duplicates('TEXT', inplace=True) # There are duplicates after the .replace() functions\n",
    "    return keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parsed_dfs(path_to_text, path_to_excel, count_limit=5):\n",
    "    vectors_df = get_vectors_df(path_to_text)\n",
    "    keywords_df = get_keywords_df(path_to_excel, count_limit=count_limit)\n",
    "    joint_df = vectors_df.merge(keywords_df)\n",
    "    vectors_df = joint_df.iloc[:, :vectors_df.shape[1]]\n",
    "    keywords_df = joint_df.iloc[:, vectors_df.shape[1]:]\n",
    "    return vectors_df, keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(vectors_df):\n",
    "    return vectors_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(matrix):\n",
    "    return np.mean(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manhattan(a, b):\n",
    "    return np.abs(a - b).sum()\n",
    "\n",
    "def get_euclidean(a, b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def get_cos_sim(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def get_corr(a, b):\n",
    "    return np.correlate(a, b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_categories(keywords_df):\n",
    "    aspect_categories = list(set(keywords_df.ASPECT_CATEGORY_NAME))\n",
    "    aspect_categories = [x for x in aspect_categories if x is not np.nan]\n",
    "    aspect_categories.sort()\n",
    "    return aspect_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(keywords_df, matrix, aspect_categories, train_size=400):\n",
    "    df_train = keywords_df.iloc[:train_size, :]\n",
    "    no_of_categories = len(aspect_categories)\n",
    "    centroids = np.zeros((no_of_categories, 300))\n",
    "    for i in range(no_of_categories):\n",
    "        indices = df_train[df_train.ASPECT_CATEGORY_NAME == aspect_categories[i]].index\n",
    "        print('{}: {}'.format(aspect_categories[i], len(indices)))\n",
    "        centroids[i] = get_centroid(matrix[indices])\n",
    "    print('\\nCentroids found.')\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(centroids, matrix, no_of_categories):  # Returns tuple of 4 matrices\n",
    "    manhattan_distances = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    euclidean_distances = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    cos_sim = np.zeros((matrix.shape[0], no_of_categories))\n",
    "    corr = np.zeros((matrix.shape[0], no_of_categories))\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            manhattan_distances[i, j] = get_manhattan(matrix[i], centroids[j])\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            euclidean_distances[i, j] = get_euclidean(matrix[i], centroids[j])\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            cos_sim[i, j] = get_cos_sim(matrix[i], centroids[j])\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(no_of_categories):\n",
    "            corr[i, j] = get_corr(matrix[i], centroids[j])\n",
    "                \n",
    "    return manhattan_distances, euclidean_distances, cos_sim, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_df(matrix, vectors_df, no_of_categories):\n",
    "    final_df = pd.DataFrame(data=matrix)\n",
    "    final_df['KEYWORD'] = vectors_df.TEXT\n",
    "    cols = ['KEYWORD'] + [i for i in range(no_of_categories)]\n",
    "    colnames = ['KEYWORD'] + [i for i in range(1, no_of_categories+1)]\n",
    "    final_df = final_df.loc[:, cols]\n",
    "    final_df.columns = colnames\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_indices(df, annotated_size, aspect_categories):\n",
    "    temp_df = df.iloc[train_size:annotated_size, :]\n",
    "    return temp_df[temp_df.ASPECT_CATEGORY_NAME.isin(aspect_categories)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, keywords_df, test_indices):\n",
    "    sum = (model.PREDICTION[test_indices] == keywords_df.ASPECT_CATEGORY_NAME[test_indices]).sum()\n",
    "    print(\"Accuracy: {}\".format(sum/len(test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
