{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/zyf0717/git_environment/STB_social_media_analytics/'\n",
      "/home/jia/Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment\n"
     ]
    }
   ],
   "source": [
    "# Amend to set wd to STB_social_media_analytics.\n",
    "%cd /home/zyf0717/git_environment/STB_social_media_analytics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import re\n",
    "import yaml\n",
    "import utils\n",
    "from random import random\n",
    "from selenium import webdriver\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_file.yml') as file:\n",
    "    configs = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "chromedriver_path = configs['General']['chromedriver_path']\n",
    "\n",
    "db_in_flag = configs['TripAdvisor']['db_in_flag']\n",
    "db_out_flag = configs['TripAdvisor']['db_out_flag']\n",
    "\n",
    "if db_in_flag == 'csv':\n",
    "    \n",
    "    ### FOR POC ONLY ### \n",
    "    poi_index = [1, 2]\n",
    "    poi_name = ['Gardens by the Bay', \n",
    "                'Marina Bay Sands Skypark'\n",
    "               ]\n",
    "    poi_url = ['https://www.tripadvisor.com.sg/Attraction_Review-g294265-d2149128-Reviews-Gardens_by_the_Bay-Singapore.html',\n",
    "               'https://www.tripadvisor.com.sg/Attraction_Review-g294265-d1837767-Reviews-Marina_Bay_Sands_Skypark-Singapore.html'\n",
    "              ]\n",
    "    poi_df = pd.DataFrame({'poi_index':poi_index, \n",
    "                           'poi_name':poi_name, \n",
    "                           'poi_url':poi_url}\n",
    "                         )\n",
    "    ####################\n",
    "\n",
    "if db_in_flag in ['sqlite', 'mysql']:\n",
    "    poi_df = pd.DataFrame()\n",
    "\n",
    "if db_in_flag in ['sqlite', 'mysql'] or db_out_flag in ['sqlite', 'mysql']:\n",
    "    cnx = mysql.connector.connect(host=configs['General']['host'],\n",
    "                                  database=configs['General']['database'],\n",
    "                                  user=configs['General']['user'],\n",
    "                                  password=configs['General']['password']\n",
    "                                 )\n",
    "else:\n",
    "    cnx = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlTripAdvisor:\n",
    "    attributes_col_names = ['POI_INDEX',\n",
    "                            'TOTAL_REVIEWS',\n",
    "                            'RANKING',\n",
    "                            'AVERAGE_RATING',\n",
    "                            'RATING_5_COUNT',\n",
    "                            'RATING_4_COUNT',\n",
    "                            'RATING_3_COUNT',\n",
    "                            'RATING_2_COUNT',\n",
    "                            'RATING_1_COUNT',\n",
    "                            'ABOUT',\n",
    "                            'ADDRESS',\n",
    "                            'ATTRIBUTES_CRAWLED_TIME'\n",
    "                           ]\n",
    "\n",
    "    reviews_col_names = ['REVIEW_INDEX',\n",
    "                         'WEBSITE_INDEX',\n",
    "                         'POI_INDEX',\n",
    "                         'REVIEWER_URL',\n",
    "                         'REVIEW_ID',\n",
    "                         'REVIEW_DATE',\n",
    "                         'REVIEW_RATING',\n",
    "                         'REVIEW_TITLE',\n",
    "                         'REVIEW_BODY',\n",
    "                         'DATE_OF_EXPERIENCE',\n",
    "                         'TRIP_TYPE',\n",
    "                         'REVIEW_CRAWLED_TIME'\n",
    "                        ]\n",
    "    \n",
    "    reviewers_col_names = ['REVIEWER_URL',\n",
    "                           'REVIEWER_NAME',\n",
    "                           'RAW_HOME_LOCATION',\n",
    "                           'CLEANED_HOME_LOCATION',\n",
    "                           'NUMBER_OF_CONTRIBUTIONS',\n",
    "                           'HELPFUL_VOTES',\n",
    "                           'REVIEWER_UPDATED_TIME'\n",
    "                          ]\n",
    "    \n",
    "    \n",
    "    def __init__(self, chromedriver_path, poi_df, cnx, db_out_flag):\n",
    "        self.driver = webdriver.Chrome(chromedriver_path)\n",
    "        if cnx is not None:\n",
    "            self.cursor = cnx.cursor()\n",
    "        self.poi_df = poi_df\n",
    "        self.db_out_flag = db_out_flag\n",
    "\n",
    "        self.number_of_pages = None\n",
    "        self.earliest_date = None\n",
    "        self.attributes_df = pd.DataFrame(columns=self.attributes_col_names)\n",
    "        self.reviews_df = pd.DataFrame(columns=self.reviews_col_names)\n",
    "        self.reviewers_df = pd.DataFrame(columns=self.reviewers_col_names)\n",
    "        \n",
    "        # Create unique CSVs.\n",
    "        self.datetime_string = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "        self.attributes_df.to_csv('./tripadvisor/output/attributes_{}.csv'.format(self.datetime_string), mode='a', index=False)\n",
    "        self.reviews_df.to_csv('./tripadvisor/output/reviews_{}.csv'.format(self.datetime_string), mode='a', index=False)\n",
    "        self.reviewers_df.to_csv('./tripadvisor/output/reviewers_{}.csv'.format(self.datetime_string), mode='a', index=False)\n",
    "                \n",
    "    \n",
    "    def add_to_database(self):\n",
    "        # Read csv, add to database, then cnx.commit().\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def crawl_pois(self, number_of_pages=None, earliest_date=None):\n",
    "        self.number_of_pages = number_of_pages\n",
    "        self.earliest_date = earliest_date\n",
    "        for _, row in poi_df.iterrows():\n",
    "            self.driver.get(row['poi_url'])\n",
    "            self.crawl_attributes(row['poi_index'])\n",
    "            self.crawl_reviews(row['poi_index'])\n",
    "            self.attributes_df.to_csv('./tripadvisor/output/attributes_{}.csv'.format(self.datetime_string), mode='a', header=False, index=False)\n",
    "            self.attributes_df = pd.DataFrame(columns=self.attributes_col_names)\n",
    "        \n",
    "    \n",
    "    def crawl_reviews(self, poi_index):\n",
    "        if self.earliest_date is not None:\n",
    "            # Crawl up till earliest_date.\n",
    "            pass\n",
    "        elif self.number_of_pages is not None:\n",
    "            for i in range(self.number_of_pages):\n",
    "                self.crawl_reviews_1_page(poi_index)\n",
    "                self.reviews_df.to_csv('./tripadvisor/output/reviews_{}.csv'.format(self.datetime_string), mode='a', header=False, index=False)\n",
    "                self.reviewers_df.to_csv('./tripadvisor/output/reviewers_{}.csv'.format(self.datetime_string), mode='a', header=False, index=False)\n",
    "                self.reviews_df = pd.DataFrame(columns=self.reviews_col_names)\n",
    "                self.reviewers_df = pd.DataFrame(columns=self.reviewers_col_names)\n",
    "        else:\n",
    "            # Crawl all pages.\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    def crawl_attributes(self, poi_index):\n",
    "        driver = self.driver\n",
    "        \n",
    "        # Crawling attributes elements.\n",
    "        ranking_text = driver.find_element_by_xpath('//span[@class=\"header_popularity popIndexValidation \"]').text\n",
    "        rating_breakdown_elements = driver.find_elements_by_xpath('//span[@class=\"location-review-review-list-parts-ReviewRatingFilter__row_num--3cSP7\"]')\n",
    "        address_text_1 = driver.find_element_by_xpath('//span[@class=\"street-address\"]').text\n",
    "        address_text_2 = driver.find_element_by_xpath('//span[@class=\"extended-address\"]').text\n",
    "        address_text_3 = driver.find_element_by_xpath('//span[@class=\"locality\"]').text\n",
    "        address_text_4 = driver.find_element_by_xpath('//span[@class=\"country-name\"]').text\n",
    "        about_more_button = driver.find_elements_by_xpath('//span[@class=\"attractions-attraction-detail-about-card-Description__readMore--2pd33\"]')\n",
    "        if about_more_button != []:\n",
    "            about_more_button[0].click()\n",
    "            sleep(0.5)\n",
    "            about_text = driver.find_element_by_xpath('//div[@class=\"attractions-attraction-detail-about-card-Description__modalText--1oJCY\"]').text\n",
    "            about_more_close_button = driver.find_element_by_xpath('//div[@class=\"_2EFRp_bb\"]')\n",
    "            about_more_close_button.click()\n",
    "            sleep(0.5)\n",
    "        else:\n",
    "            about_text = driver.find_element_by_xpath('//div[@class=\"attractions-attraction-detail-about-card-AttractionDetailAboutCard__section--1_Efg\"]').text\n",
    "        \n",
    "        # Parsing attributes.\n",
    "        rating_breakdown = self.parse_rating_breakdown_elements(rating_breakdown_elements)\n",
    "        total_reviews = self.calculate_total_reviews(rating_breakdown)\n",
    "        ranking = self.parse_ranking_text(ranking_text)\n",
    "        average_rating = self.calculate_average_rating(rating_breakdown)\n",
    "        about = about_text\n",
    "        address = self.parse_address_text(address_text_1, \n",
    "                                          address_text_2, \n",
    "                                          address_text_3, \n",
    "                                          address_text_4\n",
    "                                         )\n",
    "        \n",
    "        poi_attributes = [poi_index,\n",
    "                          total_reviews, \n",
    "                          ranking, \n",
    "                          average_rating, \n",
    "                          rating_breakdown[0],\n",
    "                          rating_breakdown[1],\n",
    "                          rating_breakdown[2],\n",
    "                          rating_breakdown[3],\n",
    "                          rating_breakdown[4],\n",
    "                          about, \n",
    "                          address, \n",
    "                          datetime.now()\n",
    "                         ]\n",
    "        \n",
    "        # Inserting attributes into dataframe\n",
    "        poi_attributes_dict = dict(zip(self.attributes_col_names, poi_attributes))\n",
    "        self.attributes_df = self.attributes_df.append(poi_attributes_dict, ignore_index=True)\n",
    "\n",
    "    def crawl_reviews_1_page(self, poi_index, earliest_date=None):        \n",
    "        driver = self.driver\n",
    "        \n",
    "        # If crawl all languages, uncomment the follwing 3 lines.\n",
    "        # all_languages_button = driver.find_element_by_xpath('//span[@class=\"location-review-review-list-parts-LanguageFilter__no_wrap--2Dckv\"]')\n",
    "        # all_languages_button.click()\n",
    "        # sleep(1)\n",
    "        \n",
    "        read_more_button = driver.find_element_by_xpath('//span[@class=\"location-review-review-list-parts-ExpandableReview__cta--2mR2g\"]')\n",
    "        read_more_button.click()\n",
    "        sleep(1)\n",
    "\n",
    "        # Crawling review elements.\n",
    "        reviewer_url_elements = driver.find_elements_by_xpath('//a[@class=\"ui_header_link social-member-event-MemberEventOnObjectBlock__member--35-jC\"]')\n",
    "        reviewer_details_elements = driver.find_elements_by_xpath('//div[@class=\"social-member-event-MemberEventOnObjectBlock__event_wrap--1YkeG\"]')\n",
    "        review_id_elements = driver.find_elements_by_xpath('//div[@class=\"location-review-review-list-parts-SingleReview__mainCol--1hApa\"]')\n",
    "        review_rating_elements = driver.find_elements_by_xpath('//div[@class=\"location-review-review-list-parts-RatingLine__bubbles--GcJvM\"]/span')\n",
    "        review_title_elements = driver.find_elements_by_xpath('//a[@class=\"location-review-review-list-parts-ReviewTitle__reviewTitleText--2tFRT\"]')\n",
    "        review_body_elements = driver.find_elements_by_xpath('//div[@class=\"location-review-review-list-parts-ExpandableReview__containerStyles--1G0AE\"]')\n",
    "        date_of_experience_elements = driver.find_elements_by_xpath('//span[@class=\"location-review-review-list-parts-EventDate__event_date--1epHa\"]')\n",
    "        \n",
    "        for i in range(len(reviewer_url_elements)):\n",
    "            \n",
    "            # Parsing review and reviewer details\n",
    "            reviewer_url = reviewer_url_elements[i].get_attribute('href')\n",
    "            reviewer_name = reviewer_url_elements[i].text\n",
    "            review_id = self.parse_review_id_elements(review_id_elements[i].get_attribute('data-reviewid'))\n",
    "            review_date = self.parse_review_date(reviewer_details_elements[i].text)\n",
    "            location_contribution_votes = self.parse_location_contributions_votes(reviewer_details_elements[i].text)\n",
    "            review_rating = self.parse_review_rating(review_rating_elements[i].get_attribute('class'))\n",
    "            review_title = review_title_elements[i].text\n",
    "            review_body = self.parse_review_body(review_body_elements[i].text)\n",
    "            date_of_experience = self.parse_date_of_experience(review_body_elements[i].text)\n",
    "            trip_type = self.parse_trip_type(review_body_elements[i].text)\n",
    "            \n",
    "            review_details = [None, # REVIEW_INDEX\n",
    "                              1, # WEBSITE_INDEX (TripAdvisor is '1')\n",
    "                              poi_index,\n",
    "                              reviewer_url,\n",
    "                              review_id,\n",
    "                              review_date,\n",
    "                              review_rating,\n",
    "                              review_title,\n",
    "                              review_body,\n",
    "                              date_of_experience,\n",
    "                              trip_type,\n",
    "                              datetime.now()\n",
    "                             ]\n",
    "            \n",
    "            reviewer_details = [reviewer_url,\n",
    "                                reviewer_name,\n",
    "                                location_contribution_votes[0],\n",
    "                                None, # CLEANED_HOME_LOCATION\n",
    "                                location_contribution_votes[1],\n",
    "                                location_contribution_votes[2],\n",
    "                                datetime.now()\n",
    "                               ]\n",
    "            \n",
    "            # Inserting reviews into dataframe.\n",
    "            review_details_dict = dict(zip(self.reviews_col_names, review_details))\n",
    "            self.reviews_df = self.reviews_df.append(review_details_dict, ignore_index=True)\n",
    "            \n",
    "            # Inserting reviewers into dataframe.\n",
    "            reviewer_details_dict = dict(zip(self.reviewers_col_names, reviewer_details))\n",
    "            self.reviewers_df = self.reviewers_df.append(reviewer_details_dict, ignore_index=True)\n",
    "\n",
    "        next_button = driver.find_element_by_xpath('//a[@class=\"ui_button nav next primary \"]')\n",
    "        if next_button != []:\n",
    "            next_button.click()\n",
    "            sleep(1)\n",
    "    \n",
    "    # Methods below are all utility functions.\n",
    "    def calculate_total_reviews(self, rating_breakdown):\n",
    "        return sum(rating_breakdown)\n",
    "    \n",
    "    \n",
    "    def parse_ranking_text(self, text):\n",
    "        return int(text[1:text.find(' of')].replace(',', ''))\n",
    "    \n",
    "    \n",
    "    def calculate_average_rating(self, rating_breakdown):\n",
    "        total = sum(rating_breakdown)\n",
    "        average = 0\n",
    "        for i, j in enumerate(rating_breakdown[::-1]):\n",
    "            average += (i+1)*j/total\n",
    "        return average\n",
    "    \n",
    "    \n",
    "    def parse_rating_breakdown_elements(self, elements):\n",
    "        rating_breakdown = []\n",
    "        for element in elements:\n",
    "            text = element.text\n",
    "            rating_breakdown.append(int(text.replace(\",\", \"\")))\n",
    "        return rating_breakdown\n",
    "    \n",
    "    \n",
    "    def parse_address_text(self, text_1, text_2, text_3, text_4):\n",
    "        return ('{}, {}, {} {}'.format(text_1, text_2, text_3, text_4))\n",
    "    \n",
    "    \n",
    "    def parse_review_date(self, text):\n",
    "        date_string = text[text.find('wrote a review ')+15:text.find('\\n')]\n",
    "        \n",
    "        if date_string == 'Today':\n",
    "            return datetime.now().strftime('%d-%m-%Y')\n",
    "        elif date_string == 'Yesterday':\n",
    "            return (datetime.now() - timedelta(1)).strftime('%d-%m-%Y')\n",
    "        \n",
    "        re_search = re.search('(\\d+) (\\w+)', date_string)\n",
    "        current_year = datetime.now().strftime('%Y')\n",
    "        if re_search is not None:\n",
    "            if len(re_search.group(1)) == 1:\n",
    "                return datetime.strptime('0' + date_string + ' ' + current_year, '%d %b %Y').strftime('%d-%m-%Y')\n",
    "            else:\n",
    "                return datetime.strptime(date_string + ' ' + current_year, '%d %b %Y').strftime('%d-%m-%Y')\n",
    "        \n",
    "        return datetime.strptime(date_string, '%b %Y').strftime('%m-%Y')                     \n",
    "    \n",
    "    \n",
    "    def parse_location_contributions_votes(self, text):\n",
    "        location, contributions, votes = None, None, None\n",
    "        \n",
    "        votes_search = re.search('(\\d+) helpful votes?', text)\n",
    "        if votes_search is not None:\n",
    "            votes = int(votes_search.group(1))\n",
    "                \n",
    "        contributions_search = re.search('(\\d+) contributions?', text)\n",
    "        if contributions_search is not None:\n",
    "            contributions = int(contributions_search.group(1))\n",
    "\n",
    "        location_search = re.search('(.+?){} contributions?'.format(contributions), text)\n",
    "        if location_search is not None:\n",
    "            location = location_search.group(1)\n",
    "\n",
    "        return location, contributions, votes\n",
    "    \n",
    "    \n",
    "    def parse_review_id_elements(self, text):\n",
    "        return int(text)\n",
    "    \n",
    "    \n",
    "    def parse_review_rating(self, text):\n",
    "        return int(text[-2:])//10\n",
    "    \n",
    "    \n",
    "    def parse_review_body(self, text):\n",
    "        return text[:text.find('Read less')-1]\n",
    "    \n",
    "    \n",
    "    def parse_date_of_experience(self, text):\n",
    "        substring = re.search('Date of experience: (.+)\\n', text).group(1)\n",
    "        return datetime.strptime(substring, '%B %Y').strftime('%m-%Y')  \n",
    "    \n",
    "    \n",
    "    def parse_trip_type(self, text):\n",
    "        if text.find('Trip type: ') == -1:\n",
    "            return None\n",
    "        substring = text[text.find('Trip type: ')+11:]\n",
    "        return substring[:substring.find('\\n')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrawlTripAdvisor(chromedriver_path, poi_df, cnx, db_out_flag).crawl_pois(number_of_pages=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200116_152740'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', 'Jan']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'12 Jan'.split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
