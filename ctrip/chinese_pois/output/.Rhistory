df <- df_raw[!(df_raw$OVERALL=="s 400 – Bad Re"| df_raw$OVERALL == "" |df_raw$ASPECTS == "[]"),]
#create two new column with paired aspect and polarity
x= as.character(df$ASPECTS)
x[[1]]
library(tidyr)
x = str_remove(x,"[")
install.packages("tidyverse")
install.packages(c("callr", "digest", "dplyr", "jsonlite", "knitr", "mime", "processx", "ps", "rlang", "rstudioapi", "stringi", "tidyselect", "vctrs", "yaml"))
install.packages(c("callr", "digest", "dplyr", "jsonlite", "knitr", "mime", "processx", "ps", "rlang", "rstudioapi", "stringi", "tidyselect", "vctrs", "yaml"))
install.packages(c("callr", "digest", "dplyr", "jsonlite", "knitr", "mime", "processx", "ps", "rlang", "rstudioapi", "stringi", "tidyselect", "vctrs", "yaml"))
version
library(installr)
?gsub
gsub("[","",df$ASPECTS)
gsub("[]","",df$ASPECTS)
gsub("[","",df$ASPECTS)
df$ASPECTS[1]
a = as.character(df$ASPECTS[1])[2:-2]
a = as.character(df$ASPECTS[1])
a
a[2]
gsub("[","",a)
install.packages('stringr')
library(stringr)
str_replace_all(a,"[[:punct:]]"," ")
library(ggplot2)
library(dplyr)
library(stringr)
df_raw <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/200218_090222_sentiment.csv")
#remove empty or 404
df <- df_raw[!(df_raw$OVERALL=="s 400 – Bad Re"| df_raw$OVERALL == "" |df_raw$ASPECTS == "[]"),]
#obtain the length of ASPECTS list
length(strsplit(as.character(df_raw[1,'ASPECTS']),',')[[1]])
#obtain the number of columns we should separate
a=vector()
for (i in 1:nrow(df_raw)){
a[i]=length(strsplit(as.character(df_raw[i,'ASPECTS']),',')[[1]])
}
max(a)
#create two new column with paired aspect and polarity
x= as.character(df$ASPECTS)
z = as.character(df$ASPECTS_POLARITIES)
j=list()
for (i in 1:length(x)) {
a=str_replace_all(x[i],"[[:punct:]]"," ")
j[i] = strsplit(a," ")
}
j
View(j)
j=list()
for (i in 1:length(x)) {
a=str_replace_all(x[i],"[[:punct:]]","")
j[i] = strsplit(a," ")
}
View(j)
x= as.character(df$ASPECTS)
z = as.character(df$ASPECTS_POLARITIES)
j=list()
for (i in 1:length(x)) {
a=str_replace_all(x[i],"[[:punct:]]",",")
j[i] = strsplit(a,",")
}
View(j)
a=str_replace_all(x[1],"[[:punct:]]",",")
a
x[1]
x= as.character(df$ASPECTS)
x[1]
strsplit('a')
strsplit('a',',')
strsplit(a,',')
b=strsplit(a,',')
b
b[b!=""]
a[lapply(a,length)>0]
b[lapply(b,length)>0]
b[lapply(b,length>0)]
l[lapply(l,length)>0]
b[lapply(b,length)>0]
b[b==""]
b[!(b=="")]
b[!(b==""),]
b[!(b=="")]
b %>%
mutate_all(~ifelse(. %in% c("N/A", "null", ""), NA, .)) %>%
na.omit()
seq(2,20,length.out=20)
?seq
####dealing wiht matrics#######
sample=c(1,3,4,6,7,NA,NA,9)
mean(sample,na.rm=TRUE)
table(is,na(sample))
table(is.na(sample))
df <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/GBB_cleaned.csv")
df <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/GBB_cleaned.csv")
View(df)
View(df)
?gather
library(tidyr)
?gather
data_long <- gather(df, 'ASPECT', 'POLARITY', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(data_long)
heart <- read.csv("~/Downloads/heart.csv")
View(heart)
View(data_long)
data_long <- gather(df, 'ASPECT', 'POLARITY', 'ASPECT0':'ASPECT35', factor_key=TRUE)
summary(heart)
data_long <- gather(df, 'REVIEW_INDEX', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(data_long)
summary(heart)
head(heart)
str(hear)
str(heart)
data_long <- gather(df, 'REVIEW_INDEX', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(data_long)
data_long <- gather(df, 'REVIEW_INDEX', 'ASPECTS', 'REVIEW_INDEX','ASPECT0':'ASPECT35', factor_key=TRUE)
View(df)
data_long <- gather(df, 'REVIEW_INDEX', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(data_long)
data_long <- gather(df, 'REVIEW_INDEX', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=FALSE)
View(data_long)
data_long[-c("ASPECT0")]
df=subset(data_long,-c("ASPECT0"))
DF=data_long[c("ASPECT","REVIEW_INDEX")]
DF=data_long[c("ASPECTS","REVIEW_INDEX")]
View(DF)
data_long <- gather(df, 'Aspect_Seq', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(data_long)
data_long1 <- gather(df_long, 'Aspect_Seq', 'POLARITIES', 'ASPECT_POLARITY0':'ASPECT_POLARITY35', factor_key=TRUE)
data_long <- gather(df, 'Aspect_Seq', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
data_long1 <- gather(df_long, 'Aspect_Seq', 'POLARITIES', 'ASPECT_POLARITY0':'ASPECT_POLARITY35', factor_key=TRUE)
data_long1 <- gather(data_long, 'Aspect_Seq', 'POLARITIES', 'ASPECT_POLARITY0':'ASPECT_POLARITY35', factor_key=TRUE)
View(data_long1)
#empty, bad request, nan
data= datalong1[!(df_long1$ASPECTS==""| df_long1 == "nan" |df_long1$ASPECTS == "tus 400 – Bad Requ	"),]
#empty, bad request, nan
data= data_long1[!(df_long1$ASPECTS==""| df_long1 == "nan" |df_long1$ASPECTS == "tus 400 – Bad Requ	"),]
#empty, bad request, nan
data= data_long1[!(data_long1$ASPECTS==""| data_long1 == "nan" |data_long1$ASPECTS == "tus 400 – Bad Requ	"),]
library(dplyr)
library(tidyr)
df <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/GBB_cleaned.csv")
data_long <- gather(df, 'Aspect_Seq', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
data_long1 <- gather(data_long, 'Aspect_Seq', 'POLARITIES', 'ASPECT_POLARITY0':'ASPECT_POLARITY35', factor_key=TRUE)
#empty, bad request, nan
data <- data_long1[!(data_long1$ASPECTS==""| data_long1 == "nan" |data_long1$ASPECTS == "tus 400 – Bad Requ	"),]
View(data)
data <- data_long1[!(data_long1$ASPECTS==""),]
View(data)
#empty, bad request, nan
data <- data_long1[!(data_long1$ASPECTS=="" | data_long1$ASPECTS=="tus 400 – Bad Requ	"),]
View(data)
#empty, bad request, nan
data <- data_long1[!(data_long1$ASPECTS=="" | data_long1$OVERALL=="s 400 – Bad Re"),]
View(data)
#empty, bad request, nan
data <- data_long1[!( data_long1$OVERALL=="s 400 – Bad Re" | data_long1$OVERALL==""),]
#empty, bad request, nan
data <- data_long1[!( data_long1$OVERALL=="s 400 – Bad Re" | data_long1$ASPECTS==""),]
#empty, bad request, nan
data <- data_long1[!( data_long1$OVERALL=="s 400 – Bad Re" | data_long1$ASPECTS=="" |data_long1$ASPECTS=="nan"),]
#empty, bad request, nan
data <- data_long1[!( data_long1$OVERALL=="s 400 – Bad Re" | data_long1$ASPECTS=="" |data_long1$ASPECTS=="nan"|data_long1$POLARITIES==""),]
summary(data)
View(df)
library(dplyr)
library(tidyr)
df <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/GBB_cleaned.csv")
long <- gather(df, 'Aspect_Seq', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(long)
data <- long[!(long$OVERALL=="s 400 – Bad Re" | long$ASPECTS=="" |long$ASPECTS=="nan"]),]
View(data)
library(dplyr)
library(tidyr)
df <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/GBB_cleaned.csv")
long <- gather(df, 'Aspect_Seq', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(df)
data <- df[!(df$OVERALL==""|df$OVERALL="s 400 – Bad Re	")]
data <- df[!(df$OVERALL==""|df$OVERALL="s 400 – Bad Re	"),]
data <- df[!(df$OVERALL=="" | df$OVERALL="s 400 – Bad Re"),]
library(dplyr)
library(tidyr)
df <- read.csv("Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/GBB_cleaned.csv")
data <- df[!(df$OVERALL=="" | df$OVERALL="s 400 – Bad Re"),]
data <- df[!(df1$OVERALL=="s 400 – Bad Re" | df$OVERALL==""),]
data <- df[!(df$OVERALL=="s 400 – Bad Re" | df$OVERALL==""),]
View(data)
long <- gather(data, 'Aspect_Seq', 'ASPECTS', 'ASPECT0':'ASPECT35', factor_key=TRUE)
View(long)
data1<- long[!(long$ASPECTS==""),]
View(data1)
long1 <- gather(data1, 'Aspect_Seq', 'POLARITIES', 'ASPECT_POLARITY0':'ASPECT_POLARITY35', factor_key=TRUE)
data1<- long1[!(long1$POLARITIES==""),]
View(data1)
View(data1)
?reshape
try <- reshape(df,varying=c("ASPECT0":"ASPECT35"),v.names="ASPECTS")
summary(df)
data <- df[!(df$OVERALL=="s 400 – Bad Re" | df$OVERALL=="" |df$ASPECT_POLARITY=="nan"),]
summary(data)
data <- df[!(df$OVERALL=="s 400 – Bad Re" | df$OVERALL=="" |df$ASPECT_POLARITY0=="nan"),]
summary(data)
data <- df[!(df$OVERALL=="s 400 – Bad Re" | df$OVERALL=="" |df$ASPECT_POLARITY0=="nan" |df$ASPECT_POLARITY0=""),]
data <- df[!(df$OVERALL=="s 400 – Bad Re" | df$OVERALL=="" |df$ASPECT_POLARITY0=="nan" |df$ASPECT_POLARITY1=""),]
`200218_090222_sentiment` <- read.csv("~/Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/200218_090222_sentiment.csv")
View(`200218_090222_sentiment`)
df_raw <- read.csv("~/Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/200218_090222_sentiment.csv")
summary(df.raw)
#remove invalid API outputs
df <- df_raw[df_raw$OVERALL == 'POS' |
df_raw$OVERALL == 'NEU' |
df_raw$OVERALL == 'NEG']
#make all entries string, to turn into list
a=as.character(df$ASPECTS)
b=as.character(df$ASPECTS_POLARITIES)
df_raw <- read.csv("~/Desktop/git/STB_social_media_analytics/experimentation/jiaxin_experiment/Ali/200218_090222_sentiment.csv")
summary(df_raw)
df <- df_raw[df_raw$OVERALL == 'POS' |
df_raw$OVERALL == 'NEU' |
df_raw$OVERALL == 'NEG']
#remove invalid API outputs
df <- df_raw[df_raw$OVERALL == 'POS' |df_raw$OVERALL == 'NEU' |df_raw$OVERALL == 'NEG']
#remove invalid API outputs
df <- df_raw[df_raw$OVERALL == 'POS' |
df_raw$OVERALL == 'NEU' |
df_raw$OVERALL == 'NEG']
#make all entries string, to turn into list
a=as.character(df$ASPECTS)
#remove invalid API outputs
df <- df_raw[df_raw$OVERALL == 'POS' |+
df_raw$OVERALL == 'NEU' |+
df_raw$OVERALL == 'NEG']
#remove invalid API outputs
df <- df_raw[df_raw$OVERALL == 'POS' |df_raw$OVERALL == 'NEU' |df_raw$OVERALL == 'NEG']
#remove invalid API outputs
df <- df_raw[(df_raw$OVERALL == "POS" |df_raw$OVERALL == "NEU" |df_raw$OVERALL == "NEG")]
#remove invalid API outputs
df <- df_raw[df_raw$OVERALL == "POS"]
df_raw[df_raw$OVERALL == "POS"]
View(df_raw)
df_raw$OVERAL
df_raw$OVERALL == "POS"
df_raw[df_raw$OVERALL == "POS"]
#remove invalid API outputs
df <- df_raw[,(df_raw$OVERALL == "POS")]
#remove invalid API outputs
df <- df_raw[(df_raw$OVERALL == "POS"),]
#remove invalid API outputs
df <- df_raw[(df_raw$OVERALL == "POS"|
df_raw$OVERALL == "NEG"|
df_raw$OVERALL == "NEU"),]
#make all entries string, to turn into list
a=as.character(df$ASPECTS)
b=as.character(df$ASPECTS_POLARITIES)
c=list()
for (i in 1:norw(a)):{
c+=strsplit(a[i],'","')
}
c=list()
for (i in 1:norw(a)):{
c + strsplit(a[i],'","')
}
c=list()
for (i in 1:norw(a)){
c + strsplit(a[i],'","')
}
c=list()
for (i in 1:nrow(a)){
c + strsplit(a[i],'","')
}
a
nrow(a)
length(a)
c=list()
for (i in 1:length(a)){
c + strsplit(a[i],'","')
}
c <- list()
for (i in 1:length(a)){
c[i] <- strsplit(a[i],'","')
}
c
c[[1]]
c[[1]][1]
str_replace_all(c[[1]][1],"[[:punct:]]","")
li_asp <- list()
len <- list()
for (i in 1:length(c)){
li1 <- list()
for (j in 1:length(c[[i]])){
li1[j] = str_replace_all(c[[i]][j],"[[:punct:]]","")
}
li_asp[i]=li1[j]
len [i] = length(li1[j])
}
View(li_asp)
View(li1)
li_asp <- list()
len <- list()
for (i in 1:length(c)){
li1 <- list()
for (j in 1:length(c[[i]])){
li1[j] = str_replace_all(c[[i]][j],"[[:punct:]]","")
}
li_asp[i]=li1
len [i] = length(li1)
}
View(li1)
warnings()
View(li_asp)
for (j in 1:length(c[[1]])){
li1[j] = str_replace_all(c[[1]][j],"[[:punct:]]","")
}
li1
View(li1)
li1[[1]]
li_asp <- list()
len <- list()
for (i in 1:length(c)){
li1 <- list()
for (j in 1:length(c[[i]])){
li1[j] = str_replace_all(c[[i]][j],"[[:punct:]]","")
}
li_asp[[i]]=li1
len [[i]] = length(li1)
}
View(li1)
View(li_asp)
li_asp[[1]]
c <- list()
for (i in 1:length(b)){
c[i] = strsplit(b[i],'","')
}
li_pol <- list()
for (i in 1:length(c)){
li1 <- list()
for (j in 1:length(c[[i]])){
li1[j] = str_replace_all(c[[i]][j],"[[:punct:]]","")
}
li_pol[[i]]=li1
}
li_pol[[1]]
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip/chinese_pois/output")
REVIEWS = read.csv("./reviews.csv",stringsAsFactors = F)
#Date
#CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./annotation.csv", stringsAsFactors = F)
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip/chinese_pois/output")
REVIEWS = read.csv("./review.csv",stringsAsFactors = F)
#Date
#CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./annotation.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./ToAnnotate.csv",stringsAsFactors = F,na.strings = "Not Available")
cum_prop = 0.5
poi_indexes = names(table(phrases$POI_INDEX)) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip/chinese_pois/output")
REVIEWS = read.csv("./review.csv",stringsAsFactors = F)
#Date
#CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./annotation.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./ToAnnotate.csv",stringsAsFactors = F,na.strings = "Not Available")
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = names(table(phrases$POI_INDEX)) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
View(phrases_agg)
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
View(phrases_agg)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
View(id_poi_index)
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip/chinese_pois/output")
REVIEWS = read.csv("./review.csv",stringsAsFactors = F)
#Date
#CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./annotation.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./ToAnnotate.csv",stringsAsFactors = F,na.strings = "Not Available")
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = names(table(phrases$POI_INDEX)) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
#Write out the file
write.csv(merged_file, "./finalised_output/combined_annotation.csv", row.names = F)
write.csv(merged_file, "./combined_annotation.csv", row.names = F)
