select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv",stringsAsFactors = F)
#Date
CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Note:
#The key is to do annotations by POI
#Merge in already annotated text
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
#Date
CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./vocab.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./raw_data/March_Update/Ctrip_Manual_Annotation.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
#Note:
#The key is to do annotations by POI
#Merge in already annotated text
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
#Date
CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./vocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
ANNOTATED=read.csv("./vocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
#Note:
#The key is to do annotations by POI
#Merge in already annotated text
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
#Date
CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./finalised_ouputvocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
#Write out the file
#Note:
#The key is to do annotations by POI
#Merge in already annotated text
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
#Date
CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./finalised_ouput/vocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
NNOTATED=read.csv("./finalised_ouput/vocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
ANNOTATED=read.csv("./finalised_output/vocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
View(merged_file)
View(CTRIP_REVIEWS)
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
View(CTRIP_REVIEWS)
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./finalised_output/vocab.csv",stringsAsFactors = F)
ANNOTATED$TEXT=toString(ANNOTATED$TEXT)
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
View(merged_file)
View(ANNOTATED)
ANNOTATED=read.csv("./finalised_output/vocab.csv",stringsAsFactors = F)
View(ANNOTATED)
#Note:
#The key is to do annotations by POI
#Merge in already annotated text
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
#Date
#CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./finalised_output/vocab.csv",stringsAsFactors = F)
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
View(merged_file)
#Write out the file
write.csv(merged_file, "./finalised_output/combined_annotation.csv", row.names = F)
View(CTRIP_REVIEWS)
View(ANNOTATED)
View(ANNOTATED)
ANNOTATED=read.csv("./finalised_output/vocab.csv",stringsAsFactors = F,na.strings = "Not Available")
View(ANNOTATED)
?na.string
??na.string
??na.strings
#Note:
#The key is to do annotations by POI
#Merge in already annotated text
library('dplyr')
##############TB_SOCIAL_TRIPA_REVIEWS##############
setwd("/home/jia/Desktop/git/STB_social_media_analytics/ctrip")
CTRIP_REVIEWS = read.csv("./finalised_output/sentiment/reviews/1.csv",stringsAsFactors = F)
#Date
#CTRIP_REVIEWS$REVIEW_DATE = as.Date(as.numeric(CTRIP_REVIEWS$REVIEW_DATE), origin = "1899-12-30")
#Extract review_id and poi_index
id_poi_index = subset(CTRIP_REVIEWS, select = c("REVIEW_ID", "POI_INDEX"))
phrases = read.csv("./finalised_output/sentiment/sentiments_200303_085230/1_keywords_200303_085230.csv", stringsAsFactors = F)
phrases = left_join(phrases, id_poi_index, by = c("REVIEW_ID"))
#############Read in annotated file###################
ANNOTATED=read.csv("./finalised_output/vocab.csv",stringsAsFactors = F,na.strings = "Not Available")
##############Subsetting phrases by POIs##############
cum_prop = 0.5
poi_indexes = as.numeric(names(table(phrases$POI_INDEX))) #list of poi indexes
phrases_agg = subset(phrases,
phrases$POI_INDEX == poi_indexes[1],
select = c("TEXT", "POI_INDEX")    #all phrases in first poi
)
phrases_agg = phrases_agg %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))      #count of phrases
phrases_agg$fraction = phrases_agg$count/ sum(phrases_agg$count)   #fraction of each phrase
phrases_agg$cum_fraction = cumsum(phrases_agg$fraction) #%percentage covered
phrases_agg = subset(phrases_agg,
phrases_agg$cum_fraction < cum_prop,
select = c("TEXT", "count")               #phrases covering 50% of the total aspects for poi 1
)
phrases_agg$poi = poi_indexes[1]                               #insert the poi index label
names(phrases_agg)[3] = paste0("poi", poi_indexes[1])
phrases_agg = phrases_agg[, -2]
for(i in 2:length(poi_indexes)){
phrases_ind = subset(phrases,
phrases$POI_INDEX == poi_indexes[i],
select = c("TEXT", "POI_INDEX")
)
phrases_ind = phrases_ind %>%
group_by(TEXT) %>%
summarize(count = n()) %>%
arrange(desc(count))
phrases_ind$fraction = phrases_ind$count/ sum(phrases_ind$count)
phrases_ind$cum_fraction = cumsum(phrases_ind$fraction)
phrases_ind = subset(phrases_ind,
phrases_ind$cum_fraction < 0.5,
select = c("TEXT", "count"))
if (nrow(phrases_ind)==0){
print(paste("skip poi ",toString(i)))}
else {
phrases_ind$poi = poi_indexes[1]
names(phrases_ind)[3] = paste0("poi", poi_indexes[i])
phrases_ind = phrases_ind[, -2]
phrases_agg = phrases_agg %>%
full_join(phrases_ind, by = c("TEXT"))
print(paste(toString(i), ": this is ok"))}
}
phrases_agg$SENTIMENT_KEYWORD_AGG_INDEX2 = 1:nrow(phrases_agg)
##Merge in annotated file
merged_file = left_join(ANNOTATED, phrases_agg, by = c("TEXT"))
#merged_file = subset(merged_file, select = c(names(merged_file)[1:6], names(merged_file)[525], names(merged_file)[7:524]))
merged_file$ASPECT_CATEGORY_NAME = ifelse(is.na(merged_file$ASPECT_CATEGORY_NAME), "not_annotated_yet", merged_file$ASPECT_CATEGORY_NAME)
merged_file = arrange(merged_file, SENTIMENT_KEYWORD_AGG_INDEX2)
View(merged_file)
write.csv(merged_file, "./finalised_output/combined_annotation.csv", row.names = F)
