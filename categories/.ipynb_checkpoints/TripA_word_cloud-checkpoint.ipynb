{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/zyf0717/git/STB_social_media_analytics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_aspects_path = './tripadvisor/aspects_output/aspects_200221_202525.csv'\n",
    "tripa_aspects_df = pd.read_csv(tripa_aspects_path)\n",
    "tripa_aspects_df = tripa_aspects_df.dropna(axis=0).reset_index(drop=True) \n",
    "tripa_aspects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pois = set(tripa_aspects_df.POI_INDEX)\n",
    "valid_pois_idx = [tripa_aspects_df.POI_INDEX.eq(i).idxmax() for i in valid_pois]\n",
    "valid_pois_idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_poi_attraction_types = pd.DataFrame(columns=['POI_INDEX', 'ATTRACTION_TYPE'])\n",
    "\n",
    "for idx in valid_pois_idx:\n",
    "    for attraction_type in tripa_aspects_df.loc[idx][2].split(\", \"):\n",
    "        tripa_poi_attraction_types= tripa_poi_attraction_types.append(\n",
    "            {'POI_INDEX': tripa_aspects_df.loc[idx][0], \n",
    "             'ATTRACTION_TYPE': attraction_type},\n",
    "            ignore_index=True)\n",
    "\n",
    "tripa_poi_attraction_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_aspects_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_ngram_frequency(df, col_name, stop_words, n):\n",
    "    text_list = list(df[col_name])\n",
    "    stop_words = stop_words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    frequency = {}\n",
    "    for text in text_list:\n",
    "        temp = []\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^a-z ]+', '', text)\n",
    "        text = text.split(' ')\n",
    "        for word in text:\n",
    "            if word not in stop_words:\n",
    "                temp.append(word)\n",
    "        for i in range(len(temp)):\n",
    "            if i + n - 1 < len(temp):\n",
    "                word = temp[i]\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "                for j in range(n - 1):\n",
    "                    word = word + ' ' + temp[i+j+1]\n",
    "                if word in frequency:\n",
    "                    frequency[word] += 1\n",
    "                else:\n",
    "                    frequency[word] = 1\n",
    "    return frequency\n",
    "\n",
    "def merge_ngram_frequencies(df, col_name, stop_words, n):\n",
    "    merged_dicts = {}\n",
    "    for i in list(range(1, n+1)):\n",
    "        temp_dict = get_ngram_frequency(df, col_name, stop_words, i)\n",
    "        merged_dicts.update(temp_dict)\n",
    "    return merged_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_aspect_frequency = merge_ngram_frequencies(\n",
    "    tripa_aspects_df, \n",
    "    'ASPECTS', \n",
    "    stop_words, \n",
    "    n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_aspects_wordcloud = WordCloud(\n",
    "    background_color=\"white\",\n",
    "    width=1000,\n",
    "    height=1000, \n",
    "    max_words=1000,\n",
    "    relative_scaling=1,\n",
    "    random_state=42\n",
    ").generate_from_frequencies(tripa_aspect_frequency)\n",
    "\n",
    "plt.imshow(tripa_aspects_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "tripa_aspects_wordcloud.to_file('./categories/tripa_aspects_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_ibm_keywords_path = './tripadvisor/finalised_output/'\n",
    "tripa_ibm_keywords_folders = os.listdir(tripa_ibm_keywords_path)\n",
    "tripa_ibm_keywords_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_col_names = [\n",
    "  \"WEBSITE_ID\", \n",
    "  \"REVIEW_ID\", \n",
    "  \"TEXT\", \n",
    "  \"RELEVANCE\", \n",
    "  \"COUNT\", \n",
    "  \"SENTIMENT_SCORE\", \n",
    "  \"SENTIMENT_LABEL\", \n",
    "  \"SADNESS\", \n",
    "  \"JOY\", \n",
    "  \"FEAR\", \n",
    "  \"DISGUST\", \n",
    "  \"ANGER\", \n",
    "  \"MIXED_SENTIMENT\"\n",
    "]\n",
    "\n",
    "tripa_ibm_keywords_df = pd.DataFrame(columns = keywords_col_names)\n",
    "\n",
    "for folder in tripa_ibm_keywords_folders:\n",
    "    sub_folders = os.listdir(tripa_ibm_keywords_path + folder)\n",
    "    folder_2 = [f for f in sub_folders if f.find('sentiments') != -1][0]\n",
    "    path = tripa_ibm_keywords_path + folder + \"/\" + folder_2 + \"/\"\n",
    "    keywords_csv = [x for x in os.listdir(path) if x.find('keywords') != -1]\n",
    "    for csv in keywords_csv:\n",
    "        tripa_ibm_keywords_df = tripa_ibm_keywords_df.append(\n",
    "            pd.read_csv(path + csv), \n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "tripa_ibm_keywords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_ibm_keywords_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_ibm_keywords_frequency = merge_ngram_frequencies(\n",
    "    tripa_ibm_keywords_df, \n",
    "    'TEXT', \n",
    "    stop_words, \n",
    "    n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripa_ibm_keywords_wordcloud = WordCloud(\n",
    "    background_color=\"white\",\n",
    "    width=1000,\n",
    "    height=1000, \n",
    "    max_words=1000,\n",
    "    relative_scaling=1,\n",
    "    random_state=42\n",
    ").generate_from_frequencies(tripa_ibm_keywords_frequency)\n",
    "\n",
    "plt.imshow(tripa_ibm_keywords_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "tripa_ibm_keywords_wordcloud.to_file('./categories/tripa_aspects_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
