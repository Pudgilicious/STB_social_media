---
title: "TripAdvisor LDA"
author: "Zheng Yifei"
date: "2/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/git/STB_social_media_analytics")
knitr::opts_chunk$set(root.dir = "~/git/STB_social_media_analytics", echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
```

```{r}
library(tidyverse)
library(textmineR)
```


```{r}
# Aspects from TripA
tripa_aspects_path <- "./tripadvisor/output/"
tripa_aspects_csvs <- list.files(path = tripa_aspects_path, include.dirs = TRUE)[1]
tripa_aspects_df <- data.frame(matrix(nrow = 0, ncol = 3))
names(tripa_aspects_df) <- c("POI_INDEX", "ASPECTS", "ASPECTS_CRAWLED_TIME")

for (file_name in tripa_aspects_csvs) {
  path <- paste0(tripa_aspects_path, file_name)
  aspects_df <- read.csv(path, as.is = TRUE)
  tripa_aspects_df <- rbind(tripa_aspects_df, aspects_df)
}

tripa_aspects_df = tripa_aspects_df[, c(1,2)]

tripa_aspects_df_parsed <- tripa_aspects_df[1, c(1,2)]

for (i in 1:758) {
  if (i %in% tripa_aspects_df$POI_INDEX) {
    temp_df <- subset(tripa_aspects_df, POI_INDEX == i)
    text <- paste(unlist(as.list(temp_df$ASPECTS)), collapse = " ")
    tripa_aspects_df_parsed <- rbind(tripa_aspects_df_parsed, c(i, text))
  }
}

tripa_aspects_df_parsed <- tripa_aspects_df_parsed[2:468,]
```

```{r}
# Create a document term matrix
dtm <- CreateDtm(tripa_aspects_df_parsed$ASPECTS, 
                 doc_names = tripa_aspects_df_parsed$POI_INDEX, 
                 ngram_window = c(1, 2))

dim(dtm)
```

```{r}
tf <- TermDocFreq(dtm = dtm)

vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]

dtm <- dtm[ , vocabulary]

dim(dtm)
```


```{r}
# fit some LDA models and select the best number of topics
k_list <- seq(1, 50, by = 1)

model_dir <- paste0("./aspects/", "models_", digest::digest(vocabulary, algo = "sha1"))

if (!dir.exists(model_dir)) dir.create(model_dir)

model_list <- TmParallelApply(X = k_list, FUN = function(k){
  filename = file.path(model_dir, paste0(k, "_topics.rda"))

  if (!file.exists(filename)) {
    m <- FitLdaModel(dtm = dtm, k = k, iterations = 500)
    m$k <- k
    m$coherence <- CalcProbCoherence(phi = m$phi, dtm = dtm, M = 5)
    save(m, file = filename)
  } else {
    load(filename)
  }

  m
}
#, export=c("dtm", "model_dir") # export only needed for Windows machines
) 

coherence_mat <- data.frame(k = sapply(model_list, function(x) nrow(x$phi)), 
                            coherence = sapply(model_list, function(x) mean(x$coherence)), 
                            stringsAsFactors = FALSE)

plot(coherence_mat, type = "o")

# select k based on maximum average coherence
model <- model_list[which.max(coherence_mat$coherence)][[1]]
```

```{r}
##### Calculate some summary statistics etc. Which is the real value-add of textmineR

# Get the R-squared of this model
model$r2 <- CalcTopicModelR2(dtm = dtm, phi = model$phi, theta = model$theta)
model$r2

# top 5 terms of the model according to phi & phi-prime
model$top_terms <- GetTopTerms(phi = model$phi, M = 20)

# phi-prime, P(topic | words) for classifying new documents
# model$phi_prime <- CalcPhiPrime(phi = model$phi, theta = model$theta, p_docs = rowSums(dtm))
# model$top_terms_prime <- GetTopTerms(phi = model$phi_prime, M = 5)

# give a hard in/out assignment of topics in documents
model$assignments <- model$theta
model$assignments[ model$assignments < 0.05 ] <- 0
model$assignments <- model$assignments / rowSums(model$assignments)
model$assignments[ is.na(model$assignments) ] <- 0


# Get some topic labels using n-grams from the DTM
model$labels <- LabelTopics(assignments = model$assignments, 
                            dtm = dtm,
                            M = 2)

# Probabilistic coherence: measures statistical support for a topic
model$coherence <- CalcProbCoherence(phi = model$phi, dtm = dtm, M = 5)


# Number of documents in which each topic appears
model$num_docs <- colSums(model$assignments > 0)

# cluster topics together in a dendrogram
model$topic_linguistic_dist <- CalcHellingerDist(model$phi)
model$hclust <- hclust(as.dist(model$topic_linguistic_dist), "ward.D")
model$hclust$clustering <- cutree(model$hclust, k = 4)
model$hclust$labels <- paste(model$hclust$labels, model$labels[ , 1])

# make a summary table
# model$summary <- data.frame(topic     = rownames(model$phi),
                            # cluster   = model$hclust$clustering,
                            # model$labels,
                            # coherence = model$coherence,
                            # num_docs  = model$num_docs,
                            # top_terms = apply(model$top_terms, 2, function(x){
                            #   paste(x, collapse = ", ")
                            # }),
                            # top_terms_prime = apply(model$top_terms_prime, 2, function(x){
                            #   paste(x, collapse = ", ")
                            # }),
                            # stringsAsFactors = FALSE)

# View(model$summary[ order(model$hclust$clustering) , ])
```

```{r}
model$top_terms

plot(model$hclust)
rect.hclust(model$hclust, k = length(unique(model$hclust$clustering)))
```

